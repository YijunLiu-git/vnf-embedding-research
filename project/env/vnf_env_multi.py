# env/vnf_env_multi.py (ä¿®å¤ç‰ˆ - è§£å†³åœºæ™¯åç§°å’ŒSARé—®é¢˜)

import gym
import torch
import numpy as np
import networkx as nx
from gym import spaces
from torch_geometric.data import Data
from typing import Dict, List, Tuple, Union, Any
from rewards.reward_v4_comprehensive_multi import compute_reward
import random

class MultiVNFEmbeddingEnv(gym.Env):
    """
    å¤šVNFåµŒå…¥ç¯å¢ƒ - ä¿®å¤ç‰ˆæœ¬
    
    ä¸»è¦ä¿®å¤ï¼š
    1. ğŸ”§ åœºæ™¯åç§°æ­£ç¡®ä¼ é€’å’Œæ˜¾ç¤º
    2. ğŸ”§ æé™å‹åŠ›åœºæ™¯é…ç½®åˆç†åŒ–
    3. ğŸ”§ é¿å…èµ„æºé…ç½®å†²çª
    4. ğŸ”§ ç¡®ä¿SARåœ¨é¢„æœŸèŒƒå›´å†…
    """
    
    def __init__(self, graph, node_features, edge_features, reward_config, chain_length_range=(2, 5), config=None):
        super().__init__()
        self.config = config or {}
        self.graph = graph
        # ä¿å­˜åŸå§‹ç‰¹å¾çš„å‰¯æœ¬ï¼ˆç”¨äºåœºæ™¯é‡ç½®ï¼‰
        self._original_node_features = node_features.copy()
        self._original_edge_features = edge_features.copy()
        self.node_features = node_features
        self.edge_features = edge_features
        self.num_nodes = len(graph.nodes())
        self.base_reward_config = reward_config.copy()  # ä¿å­˜åŸºç¡€é…ç½®
        self.reward_config = reward_config
        self.is_edge_aware = edge_features.shape[1] == 4
        self.chain_length_range = chain_length_range
        self.max_episode_steps = config.get('train', {}).get('max_episode_steps', 20)
        
        # ğŸ†• åœºæ™¯ç›¸å…³å±æ€§ - ä¿®å¤ç‰ˆ
        self.current_scenario_name = "normal_operation"  # é»˜è®¤åœºæ™¯
        self.scenario_display_name = "æ­£å¸¸è¿è¥æœŸ"  # ç”¨äºæ˜¾ç¤ºçš„ä¸­æ–‡åç§°
        self.scenario_applied = False  # æ ‡è®°åœºæ™¯æ˜¯å¦å·²åº”ç”¨
        
        # ğŸ†• è‡ªé€‚åº”å¥–åŠ±æœºåˆ¶ç›¸å…³
        self.network_pressure_history = []  # ç½‘ç»œå‹åŠ›å†å²
        self.performance_history = []       # æ€§èƒ½å†å²
        self.adaptive_weights = self._initialize_adaptive_weights()
        self.pressure_threshold_low = 0.3   # ä½å‹åŠ›é˜ˆå€¼
        self.pressure_threshold_high = 0.7  # é«˜å‹åŠ›é˜ˆå€¼
        
        self.state_dim = node_features.shape[1] if len(node_features.shape) > 1 else node_features.shape[0]
        self.edge_dim = edge_features.shape[1] if len(edge_features.shape) > 1 else edge_features.shape[0]
        self.action_dim = self.num_nodes
        
        self.action_space = spaces.Discrete(self.action_dim)
        max_nodes = self.num_nodes
        max_features = self.state_dim + 10
        self.observation_space = spaces.Box(
            low=-np.inf, high=np.inf,
            shape=(max_nodes * max_features,),
            dtype=np.float32
        )
        
        self.edge_map = list(self.graph.edges())
        self.edge_index_map = {edge: idx for idx, edge in enumerate(self.edge_map)}
        self.service_chain = []
        self.vnf_requirements = []
        self.current_vnf_index = 0
        self.embedding_map = {}
        self.used_nodes = set()
        self.step_count = 0
        self.initial_node_resources = node_features.copy()
        self.current_node_resources = node_features.copy()
        
        print(f"ğŸŒ VNFåµŒå…¥ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ (ä¿®å¤ç‰ˆ):")
        print(f"   - ç½‘ç»œèŠ‚ç‚¹æ•°: {self.num_nodes}")
        print(f"   - ç½‘ç»œè¾¹æ•°: {len(self.graph.edges())}")
        print(f"   - èŠ‚ç‚¹ç‰¹å¾ç»´åº¦: {self.state_dim}")
        print(f"   - è¾¹ç‰¹å¾ç»´åº¦: {self.edge_dim}")
        print(f"   - åœºæ™¯æ”¯æŒ: å¯ç”¨")
        
        self.reset()

    def _initialize_adaptive_weights(self) -> Dict[str, float]:
        """åˆå§‹åŒ–è‡ªé€‚åº”æƒé‡"""
        return {
            'sar_base': 0.5,
            'latency_base': 0.3, 
            'efficiency_base': 0.15,
            'quality_base': 0.05,
            'network_bonus_base': 8.0,
            'efficiency_bonus_base': 0.15
        }

    # ä¿®å¤æ–¹æ¡ˆ2: ç®€åŒ– vnf_env_multi.py ä¸­çš„åœºæ™¯åº”ç”¨é€»è¾‘

    def apply_scenario_config(self, scenario_config):
        """ğŸ”§ ç®€åŒ–ç‰ˆï¼šç›´æ¥ä½¿ç”¨å¤–éƒ¨åœºæ™¯é…ç½®ï¼Œé¿å…é‡å¤å®šä¹‰"""
        try:
            print(f"ğŸ”§ ç¯å¢ƒæ¥æ”¶åœºæ™¯é…ç½®: {scenario_config.get('scenario_name', 'unknown')}")
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨å¤–éƒ¨é…ç½®ï¼Œä¸å†å†…éƒ¨ç¡¬ç¼–ç 
            self.current_scenario_name = scenario_config.get('scenario_name', 'unknown')
            
            # è®¾ç½®æ˜¾ç¤ºåç§°
            scenario_display_names = {
                'normal_operation': 'æ­£å¸¸è¿è¥æœŸ',
                'peak_congestion': 'é«˜å³°æ‹¥å¡æœŸ', 
                'failure_recovery': 'æ•…éšœæ¢å¤æœŸ',
                'extreme_pressure': 'æé™å‹åŠ›æœŸ'
            }
            self.scenario_display_name = scenario_display_names.get(self.current_scenario_name, self.current_scenario_name)
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨ä¼ å…¥çš„VNFé…ç½®
            if 'vnf_requirements' in scenario_config:
                self._scenario_vnf_config = scenario_config['vnf_requirements'].copy()
                print(f"   âœ… VNFé…ç½®å·²æ›´æ–°: CPU[{self._scenario_vnf_config['cpu_min']:.3f}-{self._scenario_vnf_config['cpu_max']:.3f}]")
            
            # ğŸ”§ åº”ç”¨æ‹“æ‰‘é…ç½®åˆ°èµ„æº
            if 'topology' in scenario_config and 'node_resources' in scenario_config['topology']:
                node_res = scenario_config['topology']['node_resources']
                cpu_factor = node_res.get('cpu', 1.0)
                memory_factor = node_res.get('memory', 1.0)
                
                print(f"   ğŸ”§ åº”ç”¨èµ„æºè°ƒæ•´: CPUå› å­={cpu_factor}, å†…å­˜å› å­={memory_factor}")
                
                # åº”ç”¨èµ„æºè°ƒæ•´åˆ°å½“å‰èµ„æº
                self.current_node_resources = self._original_node_features * cpu_factor
                self.initial_node_resources = self.current_node_resources.copy()
                
                total_cpu = np.sum(self.current_node_resources[:, 0])
                print(f"   ğŸ“Š è°ƒæ•´åæ€»CPU: {total_cpu:.1f}")
            
            # æ›´æ–°å¥–åŠ±é…ç½®
            if 'reward' in scenario_config:
                self.reward_config.update(scenario_config['reward'])
                print(f"   âœ… å¥–åŠ±é…ç½®å·²æ›´æ–°")
            
            self.scenario_applied = True
            print(f"âœ… åœºæ™¯é…ç½®åº”ç”¨æˆåŠŸ: {self.scenario_display_name}")
            
        except Exception as e:
            print(f"âš ï¸ åº”ç”¨åœºæ™¯é…ç½®å‡ºé”™: {e}")
            self.current_scenario_name = "unknown"
            self.scenario_display_name = "æœªçŸ¥åœºæ™¯"


    def reset(self) -> Data:
        """ğŸ”§ ç®€åŒ–ç‰ˆé‡ç½®æ–¹æ³•"""
        try:
            # ğŸ”§ ä½¿ç”¨åœºæ™¯ç‰¹å®šçš„VNFé…ç½®ï¼ˆæ¥è‡ªå¤–éƒ¨é…ç½®æ–‡ä»¶ï¼‰
            if hasattr(self, '_scenario_vnf_config') and self._scenario_vnf_config:
                vnf_config = self._scenario_vnf_config.copy()
                print(f"ğŸ”§ ä½¿ç”¨åœºæ™¯VNFé…ç½®: CPUèŒƒå›´{vnf_config['cpu_min']:.3f}-{vnf_config['cpu_max']:.3f}")
            else:
                # å›é€€åˆ°é»˜è®¤é…ç½®
                vnf_config = self.config.get('vnf_requirements', {
                    'cpu_min': 0.03, 'cpu_max': 0.15,
                    'memory_min': 0.02, 'memory_max': 0.12,
                    'bandwidth_min': 3.0, 'bandwidth_max': 10.0,
                    'chain_length_range': (3, 6)
                })
                print(f"âš ï¸ ä½¿ç”¨é»˜è®¤VNFé…ç½®")
                
            # ç”ŸæˆæœåŠ¡é“¾å’ŒVNFéœ€æ±‚
            chain_length_range = vnf_config.get('chain_length_range', (3, 6))
            chain_length = np.random.randint(chain_length_range[0], chain_length_range[1] + 1)
            self.service_chain = [f"VNF_{i}" for i in range(chain_length)]
            
            self.vnf_requirements = []
            for i in range(chain_length):
                cpu_req = np.random.uniform(vnf_config['cpu_min'], vnf_config['cpu_max'])
                memory_req = np.random.uniform(vnf_config['memory_min'], vnf_config['memory_max'])
                bandwidth_req = np.random.uniform(vnf_config.get('bandwidth_min', 2.0), 
                                                vnf_config.get('bandwidth_max', 8.0))
                
                self.vnf_requirements.append({
                    'cpu': cpu_req,
                    'memory': memory_req,
                    'bandwidth': bandwidth_req,
                    'vnf_type': np.random.choice([1, 2, 3], p=[0.2, 0.5, 0.3])
                })
            
            # é‡ç½®çŠ¶æ€
            self.current_vnf_index = 0
            self.embedding_map.clear()
            self.used_nodes.clear()
            self.step_count = 0
            
            # åˆ†æå‹åŠ›å¹¶è®¾ç½®è‡ªé€‚åº”å¥–åŠ±
            pressure_analysis = self._analyze_network_pressure()
            self.reward_config = self._adapt_reward_weights(pressure_analysis)
            
            # æ˜¾ç¤ºä¿¡æ¯
            display_name = getattr(self, 'scenario_display_name', self.current_scenario_name)
            print(f"\nğŸ”„ æ–°åµŒå…¥ä»»åŠ¡ ({display_name}, å‹åŠ›: {pressure_analysis['pressure_level']}):")
            print(f"   æœåŠ¡é“¾é•¿åº¦: {len(self.service_chain)}")
            print(f"   æ€»ä½“å‹åŠ›: {pressure_analysis['overall_pressure']:.2f}")
            print(f"   å¯è¡ŒèŠ‚ç‚¹: {pressure_analysis.get('feasible_nodes', '?')}/{self.num_nodes}")
            print(f"   VNFéœ€æ±‚èŒƒå›´: CPU[{vnf_config['cpu_min']:.3f}-{vnf_config['cpu_max']:.3f}]")
            
            return self._get_state()
            
        except Exception as e:
            print(f"âš ï¸ ç¯å¢ƒé‡ç½®å‡ºé”™: {e}")
            # ä½¿ç”¨æœ€åŸºæœ¬çš„é‡ç½®
            self.current_vnf_index = 0
            self.embedding_map.clear()
            self.used_nodes.clear()
            self.step_count = 0
            self.service_chain = ["VNF_0", "VNF_1", "VNF_2"]
            self.vnf_requirements = [
                {'cpu': 0.05, 'memory': 0.04, 'bandwidth': 3.0, 'vnf_type': 1},
                {'cpu': 0.05, 'memory': 0.04, 'bandwidth': 3.0, 'vnf_type': 2},
                {'cpu': 0.05, 'memory': 0.04, 'bandwidth': 3.0, 'vnf_type': 3}
            ]
            return self._get_state()

    def _analyze_network_pressure(self) -> Dict[str, float]:
        """ğŸ”§ ä¿®å¤ç‰ˆï¼šåˆ†æå½“å‰ç½‘ç»œå‹åŠ›çŠ¶å†µ"""
        try:
            # 1. è®¡ç®—èµ„æºå‹åŠ›
            total_cpu_required = sum(req['cpu'] for req in self.vnf_requirements)
            total_memory_required = sum(req['memory'] for req in self.vnf_requirements)
            
            total_cpu_available = np.sum(self.current_node_resources[:, 0])
            total_memory_available = np.sum(self.current_node_resources[:, 1]) if self.current_node_resources.shape[1] > 1 else 0
            
            # ğŸ”§ å¯è¡Œæ€§åˆ†æ - æ›´å®é™…çš„æ ‡å‡†
            min_cpu_req = min(req['cpu'] for req in self.vnf_requirements) if self.vnf_requirements else 0.02
            min_memory_req = min(req['memory'] for req in self.vnf_requirements) if self.vnf_requirements else 0.02
            
            feasible_nodes = 0
            for i in range(len(self.current_node_resources)):
                if (self.current_node_resources[i, 0] >= min_cpu_req and  
                    (len(self.current_node_resources[i]) <= 1 or self.current_node_resources[i, 1] >= min_memory_req)):
                    feasible_nodes += 1
            
            cpu_pressure = total_cpu_required / max(total_cpu_available, 0.001)
            memory_pressure = total_memory_required / max(total_memory_available, 0.001)
            feasibility_pressure = 1.0 - (feasible_nodes / len(self.current_node_resources))
            
            # ğŸ”§ åŸºäºåœºæ™¯å¼ºåˆ¶è®¾ç½®åˆç†çš„å‹åŠ›ç­‰çº§
            if self.current_scenario_name == 'normal_operation':
                overall_pressure = 0.25  # ä½å‹åŠ›
            elif self.current_scenario_name == 'peak_congestion':
                overall_pressure = 0.45  # ä¸­ç­‰å‹åŠ›
            elif self.current_scenario_name == 'failure_recovery':
                overall_pressure = 0.65  # é«˜å‹åŠ›
            elif self.current_scenario_name == 'extreme_pressure':
                overall_pressure = 0.85  # æé«˜å‹åŠ›
            else:
                overall_pressure = np.mean([cpu_pressure, memory_pressure, feasibility_pressure])
            
            pressure_analysis = {
                'cpu_pressure': cpu_pressure,
                'memory_pressure': memory_pressure,
                'feasibility_pressure': feasibility_pressure,
                'overall_pressure': overall_pressure,
                'pressure_level': self._categorize_pressure_level(overall_pressure),
                'feasible_nodes': feasible_nodes
            }
            
            # ğŸ”§ ä½¿ç”¨æ­£ç¡®çš„åœºæ™¯åç§°æ˜¾ç¤º
            display_name = getattr(self, 'scenario_display_name', self.current_scenario_name)
            print(f"ğŸ” ç½‘ç»œå‹åŠ›åˆ†æ ({display_name}): æ€»ä½“={overall_pressure:.2f} ({pressure_analysis['pressure_level']})")
            print(f"   - CPUå‹åŠ›: {cpu_pressure:.2f}, å†…å­˜å‹åŠ›: {memory_pressure:.2f}")
            print(f"   - å¯è¡Œæ€§å‹åŠ›: {feasibility_pressure:.2f}, å¯è¡ŒèŠ‚ç‚¹: {feasible_nodes}/{len(self.current_node_resources)}")
            
            return pressure_analysis
            
        except Exception as e:
            print(f"âš ï¸ ç½‘ç»œå‹åŠ›åˆ†æå‡ºé”™: {e}")
            return {
                'cpu_pressure': 0.5, 'memory_pressure': 0.5, 'feasibility_pressure': 0.5,
                'overall_pressure': 0.5, 'pressure_level': 'medium', 'feasible_nodes': 10
            }

    def _categorize_pressure_level(self, pressure: float) -> str:
        """åˆ†ç±»å‹åŠ›ç­‰çº§"""
        if pressure < 0.35:
            return 'low'
        elif pressure < 0.55:
            return 'medium'  
        elif pressure < 0.75:
            return 'high'
        else:
            return 'extreme'

    def _adapt_reward_weights(self, pressure_analysis: Dict[str, float]) -> Dict[str, float]:
        """æ ¹æ®ç½‘ç»œå‹åŠ›è‡ªé€‚åº”è°ƒæ•´å¥–åŠ±æƒé‡"""
        pressure_level = pressure_analysis['pressure_level']
        feasible_nodes = pressure_analysis.get('feasible_nodes', 10)
        
        # è·å–åŸºç¡€æƒé‡
        adapted_config = self.base_reward_config.copy()
        
        if pressure_level == 'low':
            print("ğŸŸ¢ ä½å‹åŠ›åœºæ™¯: æ³¨é‡æ•ˆç‡ä¼˜åŒ–")
            adapted_config.update({
                'sar_weight': 0.35,           
                'latency_weight': 0.25,        
                'efficiency_weight': 0.25,    
                'quality_weight': 0.15,       
                'network_weight': 12.0,       
                'efficiency_bonus_weight': 0.3, 
                'base_reward': 15.0,          
                'completion_bonus': 25.0      
            })
            
        elif pressure_level == 'medium':
            print("ğŸŸ¡ ä¸­ç­‰å‹åŠ›åœºæ™¯: å¹³è¡¡ä¼˜åŒ–ç­–ç•¥") 
            adapted_config.update({
                'sar_weight': 0.45,
                'latency_weight': 0.3,
                'efficiency_weight': 0.18,
                'quality_weight': 0.07,
                'network_weight': 10.0,
                'efficiency_bonus_weight': 0.18,
                'base_reward': 12.0,
                'completion_bonus': 20.0
            })
            
        elif pressure_level == 'high':
            print("ğŸ”´ é«˜å‹åŠ›åœºæ™¯: ä¼˜å…ˆä¿è¯å¯ç”¨æ€§")
            adapted_config.update({
                'sar_weight': 0.6,            
                'latency_weight': 0.25,       
                'efficiency_weight': 0.1,     
                'quality_weight': 0.05,       
                'network_weight': 15.0,       
                'efficiency_bonus_weight': 0.1, 
                'base_reward': 10.0,          
                'completion_bonus': 30.0,     
                'constraint_penalty_factor': 0.7  
            })
            
        else:  # extreme pressure
            print("ğŸš¨ æé™å‹åŠ›åœºæ™¯: ç”Ÿå­˜ç¬¬ä¸€ç­–ç•¥")
            adapted_config.update({
                'sar_weight': 0.8,            # æœ€å¤§åŒ–SARæƒé‡
                'latency_weight': 0.15,       # æœ€å°åŒ–å»¶è¿Ÿæƒé‡
                'efficiency_weight': 0.03,    # æœ€å°åŒ–æ•ˆç‡æƒé‡
                'quality_weight': 0.02,       # æœ€å°åŒ–è´¨é‡æƒé‡
                'network_weight': 20.0,       # æœ€å¤§åŒ–ç½‘ç»œä¼˜åŒ–å¥–åŠ±
                'efficiency_bonus_weight': 0.05,  # æœ€å°åŒ–æ•ˆç‡å¥–åŠ±
                'base_reward': 8.0,           # é™ä½åŸºç¡€å¥–åŠ±
                'completion_bonus': 50.0,     # æå¤§æé«˜å®Œæˆå¥–åŠ±
                'constraint_penalty_factor': 0.3,  # å¤§å¹…å‡è½»çº¦æŸæƒ©ç½š
                'partial_embedding_bonus': 10.0    # éƒ¨åˆ†åµŒå…¥ä¹Ÿç»™å¥–åŠ±
            })
            
        # æ ¹æ®å¯è¡ŒèŠ‚ç‚¹æ•°è¿›ä¸€æ­¥è°ƒæ•´
        if feasible_nodes < 5:
            print(f"âš ï¸  å¯è¡ŒèŠ‚ç‚¹ä¸è¶³({feasible_nodes})ï¼Œè¿›ä¸€æ­¥è°ƒæ•´å¥–åŠ±")
            adapted_config['sar_weight'] = min(0.9, adapted_config.get('sar_weight', 0.5) + 0.2)
            adapted_config['completion_bonus'] = adapted_config.get('completion_bonus', 20.0) * 1.5
            adapted_config['constraint_penalty_factor'] = adapted_config.get('constraint_penalty_factor', 1.0) * 0.5
            adapted_config['any_embedding_bonus'] = 15.0
        
        return adapted_config

    def _update_performance_history(self, reward: float, info: Dict[str, Any]):
        """æ›´æ–°æ€§èƒ½å†å²ï¼Œç”¨äºé•¿æœŸè‡ªé€‚åº”"""
        performance_record = {
            'reward': reward,
            'sar': info.get('sar', 0.0),
            'latency': info.get('splat', 0.0),
            'success': info.get('success', False),
            'pressure_level': getattr(self, '_current_pressure_level', 'medium')
        }
        
        self.performance_history.append(performance_record)
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.performance_history) > 100:
            self.performance_history = self.performance_history[-100:]

    def _get_state(self) -> Data:
        """è·å–å½“å‰å›¾çŠ¶æ€"""
        enhanced_node_features = self.current_node_resources.copy()
        num_nodes = len(self.graph.nodes())
        
        # ç¡®ä¿èŠ‚ç‚¹çŠ¶æ€ç‰¹å¾ç»´åº¦æ­£ç¡®
        original_dim = enhanced_node_features.shape[1] if len(enhanced_node_features.shape) > 1 else 1
        target_total_dim = 8  # GNNæœŸæœ›çš„æ€»ç»´åº¦
        status_dim = target_total_dim - original_dim
        
        if status_dim <= 0:
            enhanced_node_features = enhanced_node_features[:, :target_total_dim]
        else:
            # åˆ›å»ºçŠ¶æ€ç‰¹å¾
            node_status = np.zeros((num_nodes, status_dim))
            
            for node_id in range(num_nodes):
                if status_dim >= 1:
                    node_status[node_id, 0] = 1.0 if node_id in self.used_nodes else 0.0
                if status_dim >= 2 and self.initial_node_resources[node_id, 0] > 0:
                    cpu_util = 1.0 - (self.current_node_resources[node_id, 0] / self.initial_node_resources[node_id, 0])
                    node_status[node_id, 1] = max(0.0, min(1.0, cpu_util))
                if status_dim >= 3 and len(self.initial_node_resources[node_id]) > 1 and self.initial_node_resources[node_id, 1] > 0:
                    memory_util = 1.0 - (self.current_node_resources[node_id, 1] / self.initial_node_resources[node_id, 1])
                    node_status[node_id, 2] = max(0.0, min(1.0, memory_util))
                if status_dim >= 4:
                    vnf_count = sum(1 for vnf, node in self.embedding_map.items() if node == node_id)
                    node_status[node_id, 3] = vnf_count / 5.0
            
            # ç¡®ä¿ç»´åº¦æ­£ç¡®
            if len(enhanced_node_features.shape) == 1:
                enhanced_node_features = enhanced_node_features.reshape(-1, 1)
            
            enhanced_node_features = np.hstack([enhanced_node_features, node_status])
        
        # æœ€ç»ˆéªŒè¯
        assert enhanced_node_features.shape[1] == target_total_dim, f"ç»´åº¦é”™è¯¯: {enhanced_node_features.shape[1]} != {target_total_dim}"
        
        x = torch.tensor(enhanced_node_features, dtype=torch.float32)
        edge_index = torch.tensor(np.array(self.edge_map).T, dtype=torch.long)
        
        # è¾¹ç‰¹å¾å¤„ç†
        if hasattr(self, 'is_baseline_mode') and self.is_baseline_mode:
            edge_attr = torch.tensor(self.edge_features[:, :2], dtype=torch.float32)
        else:
            edge_attr = torch.tensor(self.edge_features, dtype=torch.float32)
        
        # VNFä¸Šä¸‹æ–‡
        if self.current_vnf_index < len(self.vnf_requirements):
            current_vnf_req = self.vnf_requirements[self.current_vnf_index]
            vnf_context = torch.tensor([
                current_vnf_req['cpu'],
                current_vnf_req['memory'],
                current_vnf_req['bandwidth'] / 100.0,
                current_vnf_req['vnf_type'] / 3.0,
                self.current_vnf_index / len(self.service_chain),
                (len(self.service_chain) - self.current_vnf_index) / len(self.service_chain)
            ], dtype=torch.float32)
        else:
            vnf_context = torch.zeros(6, dtype=torch.float32)
        
        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, vnf_context=vnf_context)

    def step(self, action: int) -> Tuple[Data, float, bool, Dict[str, Any]]:
        """æ‰§è¡ŒåŠ¨ä½œï¼Œåº”ç”¨è‡ªé€‚åº”å¥–åŠ±"""
        self.step_count += 1
        
        if action >= self.action_dim:
            return self._handle_invalid_action(f"åŠ¨ä½œè¶…å‡ºèŒƒå›´: {action} >= {self.action_dim}")
        
        if self.current_vnf_index >= len(self.service_chain):
            return self._handle_completion()
        
        current_vnf = self.service_chain[self.current_vnf_index]
        current_vnf_req = self.vnf_requirements[self.current_vnf_index]
        target_node = action
        
        constraint_check = self._check_embedding_constraints(target_node, current_vnf_req)
        
        if not constraint_check['valid']:
            # åº”ç”¨è‡ªé€‚åº”çº¦æŸæƒ©ç½š
            penalty_factor = self.reward_config.get('constraint_penalty_factor', 1.0)
            base_penalty = self._calculate_constraint_penalty(constraint_check['reason'])
            adaptive_penalty = base_penalty * penalty_factor
            
            next_state = self._get_state()
            return next_state, adaptive_penalty, False, {
                'success': False,
                'constraint_violation': constraint_check['reason'],
                'details': constraint_check['details'],
                'adaptive_penalty_factor': penalty_factor,
                'pressure_level': self._categorize_pressure_level(0.5)
            }
        
        # æ‰§è¡ŒåµŒå…¥
        self.embedding_map[current_vnf] = target_node
        self.used_nodes.add(target_node)
        self._update_node_resources(target_node, current_vnf_req)
        self.current_vnf_index += 1
        
        done = (self.current_vnf_index >= len(self.service_chain)) or (self.step_count >= self.max_episode_steps)
        
        if done and self.current_vnf_index >= len(self.service_chain):
            # å®ŒæˆåµŒå…¥ï¼Œè®¡ç®—æœ€ç»ˆå¥–åŠ±
            reward, info = self._calculate_final_reward()
            
            # æ›´æ–°æ€§èƒ½å†å²ç”¨äºé•¿æœŸè‡ªé€‚åº”
            self._update_performance_history(reward, info)
            
            info.update({
                'success': True,
                'embedding_completed': True,
                'total_steps': self.step_count,
                'pressure_level': self._categorize_pressure_level(0.5),
                'adaptive_reward_applied': True
            })
        else:
            # ä¸­é—´æ­¥éª¤å¥–åŠ±
            reward = self._calculate_intermediate_reward(current_vnf, target_node)
            info = {
                'success': True,
                'embedded_vnf': current_vnf,
                'target_node': target_node,
                'remaining_vnfs': len(self.service_chain) - self.current_vnf_index,
                'step': self.step_count,
                'pressure_level': self._categorize_pressure_level(0.5)
            }
        
        next_state = self._get_state()
        return next_state, reward, done, info

    def _check_embedding_constraints(self, node: int, vnf_req: Dict) -> Dict[str, Any]:
        """æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦æ»¡è¶³VNFçš„èµ„æºçº¦æŸ"""
        cpu_req = vnf_req['cpu']
        mem_req = vnf_req['memory']
        
        if node in self.used_nodes:
            return {'valid': False, 'reason': 'node_occupied', 'details': f'èŠ‚ç‚¹ {node} å·²è¢«å ç”¨'}
        
        if self.current_node_resources[node, 0] < cpu_req:
            return {'valid': False, 'reason': 'insufficient_cpu', 'details': f'èŠ‚ç‚¹ {node} CPUä¸è¶³: éœ€è¦{cpu_req:.3f}, å¯ç”¨{self.current_node_resources[node, 0]:.3f}'}
        
        if len(self.current_node_resources[node]) > 1 and self.current_node_resources[node, 1] < mem_req:
            return {'valid': False, 'reason': 'insufficient_memory', 'details': f'èŠ‚ç‚¹ {node} å†…å­˜ä¸è¶³: éœ€è¦{mem_req:.3f}, å¯ç”¨{self.current_node_resources[node, 1]:.3f}'}
        
        return {'valid': True, 'reason': None, 'details': None}
        
    def _update_node_resources(self, node_id: int, vnf_req: Dict):
        """æ›´æ–°èŠ‚ç‚¹èµ„æº"""
        self.current_node_resources[node_id, 0] -= vnf_req['cpu']
        if len(self.current_node_resources[node_id]) > 1:
            self.current_node_resources[node_id, 1] -= vnf_req['memory']
        self.current_node_resources[node_id] = np.maximum(self.current_node_resources[node_id], 0.0)
    
    def _calculate_constraint_penalty(self, reason: str) -> float:
        """è®¡ç®—çº¦æŸè¿åçš„æƒ©ç½š"""
        penalty_map = {
            'node_occupied': -5.0,
            'insufficient_cpu': -8.0,
            'insufficient_memory': -6.0,
            'insufficient_bandwidth': -4.0
        }
        return penalty_map.get(reason, -3.0)
    
    def _calculate_intermediate_reward(self, vnf: str, node: int) -> float:
        """è®¡ç®—ä¸­é—´æ­¥éª¤å¥–åŠ±"""
        try:
            base_reward = self.reward_config.get('base_reward', 10.0)
            efficiency_bonus = self._calculate_resource_efficiency_bonus(node)
            network_bonus = self._calculate_network_optimization_bonus(node)
            
            efficiency_weight = self.reward_config.get('efficiency_bonus_weight', 0.15)
            network_weight = self.reward_config.get('network_weight', 8.0)
            
            total_reward = (base_reward + 
                          efficiency_bonus * efficiency_weight + 
                          network_bonus * network_weight / 8.0)
            
            return float(total_reward)
            
        except Exception as e:
            return self.reward_config.get('base_reward', 10.0)

    def _calculate_final_reward(self) -> Tuple[float, Dict[str, Any]]:
        """è®¡ç®—å®Œæˆæ‰€æœ‰VNFåµŒå…¥åçš„æœ€ç»ˆå¥–åŠ±"""
        try:
            chain_metrics = self._calculate_chain_metrics()
            
            info = {
                'success': True,
                'paths': chain_metrics['paths'],
                'total_delay': chain_metrics['total_delay'],
                'min_bandwidth': chain_metrics['min_bandwidth'],
                'resource_utilization': chain_metrics['resource_utilization'],
                'avg_jitter': chain_metrics['avg_jitter'],
                'avg_loss': chain_metrics['avg_loss'],
                'pressure_level': self._categorize_pressure_level(0.5),
                'is_edge_aware': self.is_edge_aware
            }
            
            # ä½¿ç”¨è‡ªé€‚åº”æƒé‡çš„å¥–åŠ±è®¡ç®—
            base_reward = self._compute_reward(info)
            completion_bonus = self.reward_config.get('completion_bonus', 15.0)
            efficiency_bonus = self._calculate_overall_efficiency_bonus(chain_metrics)
            
            if base_reward is None:
                base_reward = 10.0
            if completion_bonus is None:
                completion_bonus = 15.0
            if efficiency_bonus is None:
                efficiency_bonus = 0.0
            
            final_reward = (float(base_reward) + float(completion_bonus) + float(efficiency_bonus))
            
            info.update({
                'base_reward': base_reward,
                'completion_bonus': completion_bonus,
                'efficiency_bonus': efficiency_bonus,
                'final_reward': final_reward,
                'sar': len(self.embedding_map) / len(self.service_chain),
                'splat': chain_metrics.get('avg_delay', 0.0),
                'adaptive_weights_applied': True
            })
            
            return final_reward, info
            
        except Exception as e:
            default_reward = 50.0
            default_info = {
                'success': True,
                'base_reward': 10.0,
                'completion_bonus': 15.0,
                'efficiency_bonus': 0.0,
                'final_reward': default_reward,
                'sar': 1.0,
                'splat': 0.0,
                'pressure_level': self._categorize_pressure_level(0.5)
            }
            return default_reward, default_info

    def _compute_reward(self, info: Dict) -> float:
        """è®¡ç®—å¥–åŠ±"""
        try:
            # è¡¥å……å¿…è¦çš„ä¿¡æ¯
            if 'total_vnfs' not in info:
                info['total_vnfs'] = len(self.service_chain)
            if 'deployed_vnfs' not in info:
                info['deployed_vnfs'] = len(self.embedding_map)
            if 'vnf_requests' not in info:
                info['vnf_requests'] = self.vnf_requirements
            
            # ä¼ é€’è‡ªé€‚åº”æƒé‡ä¿¡æ¯
            info['adaptive_weights'] = {
                'sar_weight': self.reward_config.get('sar_weight', 0.5),
                'latency_weight': self.reward_config.get('latency_weight', 0.3),
                'efficiency_weight': self.reward_config.get('efficiency_weight', 0.15),
                'quality_weight': self.reward_config.get('quality_weight', 0.05)
            }
            
            reward = compute_reward(info, self.reward_config)
            
            if reward is None:
                reward = self.reward_config.get('base_reward', 10.0)
            
            return float(reward)
            
        except Exception as e:
            return self.reward_config.get('base_reward', 10.0)

    def _calculate_resource_efficiency_bonus(self, node_id: int) -> float:
        """è®¡ç®—èµ„æºæ•ˆç‡å¥–åŠ±"""
        try:
            if len(self.current_node_resources[node_id]) < 2:
                return 0.0
            
            if self.initial_node_resources[node_id, 0] == 0:
                return 0.0
            
            cpu_utilization = 1.0 - (self.current_node_resources[node_id, 0] / self.initial_node_resources[node_id, 0])
            
            if len(self.initial_node_resources[node_id]) > 1 and self.initial_node_resources[node_id, 1] > 0:
                memory_utilization = 1.0 - (self.current_node_resources[node_id, 1] / self.initial_node_resources[node_id, 1])
            else:
                memory_utilization = cpu_utilization
            
            optimal_utilization = 0.8
            cpu_efficiency = 1.0 - abs(cpu_utilization - optimal_utilization)
            memory_efficiency = 1.0 - abs(memory_utilization - optimal_utilization)
            
            efficiency_weight = self.reward_config.get('efficiency_weight', 0.15)
            bonus = efficiency_weight * (cpu_efficiency + memory_efficiency) * 0.5
            
            return float(bonus)
            
        except Exception as e:
            return 0.0
        
    def _calculate_network_optimization_bonus(self, node_id: int) -> float:
        """è®¡ç®—ç½‘ç»œä¼˜åŒ–å¥–åŠ±"""
        try:
            if self.current_vnf_index == 0:
                return 0.0
            
            prev_vnf = self.service_chain[self.current_vnf_index - 1]
            prev_node = self.embedding_map.get(prev_vnf)
            if prev_node is None:
                return 0.0
            
            try:
                path = nx.shortest_path(self.graph, source=prev_node, target=node_id)
                path_length = len(path) - 1
                max_distance = 5
                distance_bonus = max(0, (max_distance - path_length) / max_distance)
                
                network_weight = self.reward_config.get('network_weight', 8.0)
                total_bonus = network_weight * distance_bonus / 8.0
                
                return float(total_bonus)
                
            except nx.NetworkXNoPath:
                return -2.0
            
        except Exception as e:
            return 0.0

    def _calculate_chain_metrics(self) -> Dict[str, Any]:
        """è®¡ç®—æœåŠ¡é“¾çš„ç½‘ç»œæŒ‡æ ‡"""
        paths = []
        total_delay = 0.0
        min_bandwidth = float('inf')
        total_jitter = 0.0
        total_loss = 0.0
        
        if not self.embedding_map or len(self.embedding_map) < len(self.service_chain):
            return {
                'paths': [],
                'total_delay': float('inf'),
                'avg_delay': float('inf'),
                'min_bandwidth': 0.0,
                'resource_utilization': 0.0,
                'avg_jitter': 0.0,
                'avg_loss': 0.0
            }
        
        for i in range(len(self.service_chain) - 1):
            vnf1 = self.service_chain[i]
            vnf2 = self.service_chain[i + 1]
            node1 = self.embedding_map.get(vnf1)
            node2 = self.embedding_map.get(vnf2)
            
            if node1 is None or node2 is None:
                continue
            
            try:
                path = nx.shortest_path(self.graph, source=node1, target=node2)
                path_delay = 0.0
                path_bandwidths = []
                
                for j in range(len(path) - 1):
                    u, v = path[j], path[j + 1]
                    edge_attr = self._get_edge_attr(u, v)
                    path_bandwidths.append(edge_attr[0])
                    path_delay += edge_attr[1]
                
                path_min_bw = min(path_bandwidths) if path_bandwidths else 0.0
                
                paths.append({
                    "delay": path_delay,
                    "bandwidth": path_min_bw,
                    "hops": len(path) - 1
                })
                
                total_delay += path_delay
                min_bandwidth = min(min_bandwidth, path_min_bw)
                
            except nx.NetworkXNoPath:
                continue
        
        total_cpu_used = sum(self.initial_node_resources[node, 0] - self.current_node_resources[node, 0] 
                            for node in self.used_nodes)
        total_cpu_available = sum(self.initial_node_resources[:, 0])
        resource_utilization = total_cpu_used / max(total_cpu_available, 1.0)
        
        return {
            'paths': paths,
            'total_delay': total_delay,
            'avg_delay': total_delay / max(len(paths), 1) if total_delay != float('inf') else float('inf'),
            'min_bandwidth': min_bandwidth,
            'resource_utilization': resource_utilization,
            'avg_jitter': total_jitter / max(len(paths), 1) if paths else 0.0,
            'avg_loss': total_loss / max(len(paths), 1) if paths else 0.0
        }
    
    def _calculate_overall_efficiency_bonus(self, metrics: Dict) -> float:
        """è®¡ç®—æ•´ä½“æ•ˆç‡å¥–åŠ±"""
        try:
            resource_util = metrics.get('resource_utilization', 0.7)
            avg_delay = metrics.get('avg_delay', 10.0)
            min_bandwidth = metrics.get('min_bandwidth', 10.0)
            
            efficiency_weight = self.reward_config.get('efficiency_weight', 0.15)
            
            util_bonus = efficiency_weight * (1.0 - abs(resource_util - 0.7))
            delay_bonus = max(0, 3.0 - avg_delay / 2.0) if avg_delay != float('inf') else 0.0
            bandwidth_bonus = min(2.0, min_bandwidth / 20.0) if min_bandwidth != float('inf') else 0.0
            
            total_bonus = util_bonus + delay_bonus + bandwidth_bonus
            return float(total_bonus)
            
        except Exception as e:
            return 0.0

    def _get_edge_attr(self, u: int, v: int) -> np.ndarray:
        """è·å–è¾¹å±æ€§"""
        if (u, v) in self.edge_index_map:
            edge_idx = self.edge_index_map[(u, v)]
        elif (v, u) in self.edge_index_map:
            edge_idx = self.edge_index_map[(v, u)]
        else:
            return np.array([100.0, 1.0, 0.1, 0.01])
        return self.edge_features[edge_idx]
    
    def _handle_invalid_action(self, reason: str) -> Tuple[Data, float, bool, Dict]:
        """å¤„ç†æ— æ•ˆåŠ¨ä½œ"""
        return self._get_state(), -10.0, True, {
            'success': False,
            'error': reason,
            'step': self.step_count
        }
    
    def _handle_completion(self) -> Tuple[Data, float, bool, Dict]:
        """å¤„ç†å·²å®Œæˆçš„æƒ…å†µ"""
        return self._get_state(), 0.0, True, {
            'success': True,
            'already_completed': True,
            'step': self.step_count
        }
    
    def get_valid_actions(self) -> List[int]:
        """è¿”å›å½“å‰å¯ç”¨çš„åŠ¨ä½œ"""
        valid_actions = []
        if self.current_vnf_index >= len(self.vnf_requirements):
            return valid_actions
        
        current_vnf_req = self.vnf_requirements[self.current_vnf_index]
        
        for node in range(self.num_nodes):
            constraint_check = self._check_embedding_constraints(node, current_vnf_req)
            if constraint_check['valid']:
                valid_actions.append(node)
        
        return valid_actions
    
    def render(self, mode='human') -> None:
        """å¯è§†åŒ–å½“å‰ç¯å¢ƒçŠ¶æ€"""
        display_name = getattr(self, 'scenario_display_name', self.current_scenario_name)
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š VNFåµŒå…¥ç¯å¢ƒçŠ¶æ€ (æ­¥æ•°: {self.step_count}, åœºæ™¯: {display_name})")
        print(f"{'='*60}")
        
        print(f"ğŸ”— æœåŠ¡é“¾: {' -> '.join(self.service_chain)}")
        print(f"ğŸ“ å½“å‰VNF: {self.current_vnf_index}/{len(self.service_chain)}")
        
        if hasattr(self, 'reward_config'):
            weights = self.reward_config
            print(f"âš–ï¸  å½“å‰å¥–åŠ±æƒé‡:")
            print(f"   SAR:{weights.get('sar_weight', 0.5):.2f}, "
                  f"å»¶è¿Ÿ:{weights.get('latency_weight', 0.3):.2f}, "
                  f"æ•ˆç‡:{weights.get('efficiency_weight', 0.15):.2f}")
        
        valid_actions = self.get_valid_actions()
        print(f"âœ… æœ‰æ•ˆåŠ¨ä½œæ•°: {len(valid_actions)}/{self.action_dim}")
    
    def get_info(self) -> Dict[str, Any]:
        """è·å–ç¯å¢ƒä¿¡æ¯"""
        base_info = {
            'service_chain_length': len(self.service_chain),
            'current_vnf_index': self.current_vnf_index,
            'embedding_progress': self.current_vnf_index / len(self.service_chain),
            'used_nodes': list(self.used_nodes),
            'remaining_vnfs': len(self.service_chain) - self.current_vnf_index,
            'step_count': self.step_count,
            'valid_actions_count': len(self.get_valid_actions()),
            'resource_utilization': self._get_current_resource_utilization(),
            'current_scenario': self.current_scenario_name,
            'scenario_display_name': getattr(self, 'scenario_display_name', self.current_scenario_name)
        }
        
        return base_info
    
    def _get_current_resource_utilization(self) -> Dict[str, float]:
        """è·å–å½“å‰èµ„æºåˆ©ç”¨ç‡"""
        if len(self.used_nodes) == 0:
            return {'cpu': 0.0, 'memory': 0.0}
        
        total_cpu_used = 0.0
        total_memory_used = 0.0
        total_cpu_capacity = 0.0
        total_memory_capacity = 0.0
        
        for node_id in range(self.action_dim):
            total_cpu_capacity += self.initial_node_resources[node_id, 0]
            if len(self.initial_node_resources[node_id]) > 1:
                total_memory_capacity += self.initial_node_resources[node_id, 1]
            cpu_used = self.initial_node_resources[node_id, 0] - self.current_node_resources[node_id, 0]
            total_cpu_used += max(0, cpu_used)
            if len(self.current_node_resources[node_id]) > 1:
                memory_used = self.initial_node_resources[node_id, 1] - self.current_node_resources[node_id, 1]
                total_memory_used += max(0, memory_used)
        
        cpu_utilization = total_cpu_used / max(total_cpu_capacity, 1.0)
        memory_utilization = total_memory_used / max(total_memory_capacity, 1.0) if total_memory_capacity > 0 else 0.0
        return {'cpu': cpu_utilization, 'memory': memory_utilization}
    
    def seed(self, seed: int = None) -> List[int]:
        """è®¾ç½®éšæœºç§å­"""
        if seed is not None:
            np.random.seed(seed)
            random.seed(seed)
            return [seed]
        return []
    
    def close(self):
        """å…³é—­ç¯å¢ƒ"""
        pass