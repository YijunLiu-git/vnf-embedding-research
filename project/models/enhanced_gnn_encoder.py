# models/enhanced_gnn_encoder_fixed.py - ä¿®å¤ç»´åº¦ä¸åŒ¹é…é—®é¢˜

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, GATConv, Set2Set, global_mean_pool, global_add_pool
from torch_geometric.data import Data, Batch
import numpy as np

class EdgeAttentionLayer(nn.Module):
    """
    è¾¹æ³¨æ„åŠ›å±‚ - ä¿®å¤ç‰ˆæœ¬
    """
    
    def __init__(self, edge_dim, hidden_dim, vnf_context_dim=6):
        super(EdgeAttentionLayer, self).__init__()
        
        self.edge_dim = edge_dim
        self.hidden_dim = hidden_dim
        self.vnf_context_dim = vnf_context_dim
        
        # ğŸ”§ ä¿®å¤ï¼šå¤„ç†ä¸åŒçš„è¾¹ç‰¹å¾è¾“å…¥æƒ…å†µ
        # å¦‚æœè¾¹ç‰¹å¾å·²ç»æ˜¯hidden_dimç»´åº¦ï¼Œåˆ™ä¸éœ€è¦æŠ•å½±
        self.edge_proj = nn.Linear(edge_dim, hidden_dim) if edge_dim != hidden_dim else nn.Identity()
        
        # VNFéœ€æ±‚ç¼–ç å™¨
        self.vnf_encoder = nn.Linear(vnf_context_dim, hidden_dim)
        
        # æ³¨æ„åŠ›è®¡ç®—ç½‘ç»œ
        self.attention_net = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 1),
            nn.Sigmoid()
        )
        
        # è¾¹é‡è¦æ€§åˆ†ç±»å™¨
        self.importance_classifier = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 3),
            nn.Softmax(dim=-1)
        )
        
        # å…¨å±€ç½‘ç»œçŠ¶æ€æ„ŸçŸ¥
        self.global_attention = nn.MultiheadAttention(
            embed_dim=hidden_dim,
            num_heads=4,
            dropout=0.1,
            batch_first=True
        )
        
    def forward(self, edge_attr, edge_index, vnf_context=None, network_state=None):
        """
        è®¡ç®—è¾¹æ³¨æ„åŠ›æƒé‡ - ä¿®å¤ç‰ˆæœ¬
        """
        # 1. è¾¹ç‰¹å¾ç¼–ç  - ğŸ”§ ä¿®å¤ç»´åº¦é—®é¢˜
        if edge_attr.size(-1) == self.edge_dim:
            edge_features = self.edge_proj(edge_attr)  # éœ€è¦æŠ•å½±
        elif edge_attr.size(-1) == self.hidden_dim:
            edge_features = edge_attr  # å·²ç»æ˜¯æ­£ç¡®ç»´åº¦
        else:
            # è‡ªé€‚åº”å¤„ç†
            if edge_attr.size(-1) < self.hidden_dim:
                # å¦‚æœç»´åº¦å¤ªå°ï¼Œå…ˆæŠ•å½±åˆ°hidden_dim
                temp_proj = nn.Linear(edge_attr.size(-1), self.hidden_dim).to(edge_attr.device)
                edge_features = temp_proj(edge_attr)
            else:
                # å¦‚æœç»´åº¦å¤ªå¤§ï¼Œé™ç»´åˆ°hidden_dim
                temp_proj = nn.Linear(edge_attr.size(-1), self.hidden_dim).to(edge_attr.device)
                edge_features = temp_proj(edge_attr)
        
        # 2. VNFä¸Šä¸‹æ–‡èåˆ
        if vnf_context is not None:
            try:
                if vnf_context.dim() == 1:
                    vnf_context = vnf_context.unsqueeze(0)
                vnf_embedding = self.vnf_encoder(vnf_context)  # [1, hidden_dim]
                
                # å¹¿æ’­VNFåµŒå…¥åˆ°æ‰€æœ‰è¾¹
                vnf_broadcast = vnf_embedding.expand(edge_features.size(0), -1)
                
                # èåˆè¾¹ç‰¹å¾å’ŒVNFéœ€æ±‚
                combined_features = torch.cat([edge_features, vnf_broadcast], dim=-1)
                
                # è®¡ç®—æ³¨æ„åŠ›æƒé‡
                edge_attention = self.attention_net(combined_features).squeeze(-1)
            except Exception as e:
                print(f"âš ï¸ VNFä¸Šä¸‹æ–‡å¤„ç†å¤±è´¥: {e}")
                edge_attention = torch.ones(edge_features.size(0), device=edge_features.device)
        else:
            edge_attention = torch.ones(edge_features.size(0), device=edge_features.device)
        
        # 3. å…¨å±€ç½‘ç»œçŠ¶æ€æ„ŸçŸ¥
        if network_state is not None:
            try:
                edge_features_expanded = edge_features.unsqueeze(0)
                if hasattr(network_state, 'unsqueeze'):
                    network_state_expanded = network_state.unsqueeze(0).unsqueeze(0)
                else:
                    network_state_tensor = torch.tensor(network_state, device=edge_features.device, dtype=torch.float32)
                    network_state_expanded = network_state_tensor.unsqueeze(0).unsqueeze(0)
                
                # ç¡®ä¿ç»´åº¦åŒ¹é…
                if network_state_expanded.size(-1) != self.hidden_dim:
                    state_proj = nn.Linear(network_state_expanded.size(-1), self.hidden_dim).to(edge_features.device)
                    network_state_expanded = state_proj(network_state_expanded)
                
                attended_features, _ = self.global_attention(
                    edge_features_expanded, 
                    network_state_expanded, 
                    network_state_expanded
                )
                edge_features = attended_features.squeeze(0)
            except Exception as e:
                print(f"âš ï¸ ç½‘ç»œçŠ¶æ€æ„ŸçŸ¥å¤±è´¥: {e}")
        
        # 4. è¾¹é‡è¦æ€§åˆ†ç±»
        try:
            edge_importance = self.importance_classifier(edge_features)
        except Exception as e:
            print(f"âš ï¸ è¾¹é‡è¦æ€§åˆ†ç±»å¤±è´¥: {e}")
            edge_importance = torch.ones(edge_features.size(0), 3, device=edge_features.device) / 3.0
        
        # 5. åº”ç”¨æ³¨æ„åŠ›æƒé‡
        weighted_edge_features = edge_features * edge_attention.unsqueeze(-1)
        
        return edge_attention, weighted_edge_features, edge_importance


class PathQualityAwareConv(nn.Module):
    """
    è·¯å¾„è´¨é‡æ„ŸçŸ¥å·ç§¯å±‚ - ä¿®å¤ç‰ˆæœ¬
    """
    
    def __init__(self, in_dim, out_dim, edge_dim, heads=4):
        super(PathQualityAwareConv, self).__init__()
        
        self.in_dim = in_dim
        self.out_dim = out_dim
        self.edge_dim = edge_dim
        self.heads = heads
        
        # åŸºç¡€GATå±‚
        self.gat = GATConv(
            in_channels=in_dim,
            out_channels=out_dim,
            heads=heads,
            concat=False,
            edge_dim=edge_dim,
            dropout=0.1
        )
        
        # è·¯å¾„è´¨é‡ç¼–ç å™¨
        self.path_quality_encoder = nn.Sequential(
            nn.Linear(4, edge_dim // 2),
            nn.ReLU(),
            nn.Linear(edge_dim // 2, edge_dim)
        )
        
        # è·¯å¾„çº¦æŸæ„ŸçŸ¥å±‚
        self.constraint_awareness = nn.Sequential(
            nn.Linear(out_dim + edge_dim, out_dim),
            nn.ReLU(),
            nn.Dropout(0.1)
        )
        
    def forward(self, x, edge_index, edge_attr, path_quality_info=None):
        """
        è·¯å¾„è´¨é‡æ„ŸçŸ¥çš„å›¾å·ç§¯ - ä¿®å¤ç‰ˆæœ¬
        """
        # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿edge_attrç»´åº¦æ­£ç¡®
        if edge_attr.size(-1) != self.edge_dim:
            # åŠ¨æ€è°ƒæ•´è¾¹ç‰¹å¾ç»´åº¦
            if edge_attr.size(-1) < self.edge_dim:
                padding = torch.zeros(edge_attr.size(0), self.edge_dim - edge_attr.size(-1), 
                                    device=edge_attr.device)
                edge_attr = torch.cat([edge_attr, padding], dim=-1)
            else:
                edge_attr = edge_attr[:, :self.edge_dim]
        
        # 1. åŸºç¡€å›¾å·ç§¯
        try:
            x_conv = self.gat(x, edge_index, edge_attr)
        except Exception as e:
            print(f"âš ï¸ GATå·ç§¯å¤±è´¥: {e}")
            # å›é€€åˆ°ç®€å•çš„çº¿æ€§å˜æ¢
            x_conv = nn.Linear(self.in_dim, self.out_dim).to(x.device)(x)
        
        # 2. è·¯å¾„è´¨é‡ä¿¡æ¯èåˆ
        if path_quality_info is not None:
            try:
                quality_features = self._extract_path_quality_features_safe(
                    edge_index, edge_attr, path_quality_info
                )
                enhanced_edge_attr = edge_attr + quality_features
                x_conv = self.gat(x, edge_index, enhanced_edge_attr)
            except Exception as e:
                print(f"âš ï¸ è·¯å¾„è´¨é‡èåˆå¤±è´¥: {e}")
        
        # 3. çº¦æŸæ„ŸçŸ¥å¤„ç†
        if path_quality_info is not None:
            try:
                constraint_features = self._compute_constraint_features_safe(x_conv, path_quality_info)
                x_out = self.constraint_awareness(
                    torch.cat([x_conv, constraint_features], dim=-1)
                )
            except Exception as e:
                print(f"âš ï¸ çº¦æŸæ„ŸçŸ¥å¤±è´¥: {e}")
                x_out = x_conv
        else:
            x_out = x_conv
        
        return x_out
    
    def _extract_path_quality_features_safe(self, edge_index, edge_attr, path_quality_info):
        """å®‰å…¨çš„è·¯å¾„è´¨é‡ç‰¹å¾æå–"""
        try:
            quality_matrix = path_quality_info.get('path_quality_matrix', {})
            quality_features = torch.zeros_like(edge_attr)
            
            for i, (src, dst) in enumerate(edge_index.t()):
                if i < quality_features.size(0):
                    src_idx, dst_idx = src.item(), dst.item()
                    path_info = quality_matrix.get((src_idx, dst_idx), {})
                    
                    if path_info:
                        bandwidth = path_info.get('bandwidth', 0.0)
                        latency = path_info.get('latency', 0.0)
                        jitter = path_info.get('jitter', 0.0)
                        loss = path_info.get('packet_loss', 0.0)
                        
                        quality_vec = torch.tensor([bandwidth/100, latency/100, jitter*100, loss*100], 
                                                 device=edge_attr.device)
                        
                        if hasattr(self, 'path_quality_encoder'):
                            quality_encoded = self.path_quality_encoder(quality_vec)
                            if quality_encoded.size(0) == edge_attr.size(-1):
                                quality_features[i] = quality_encoded
            
            return quality_features
        except Exception as e:
            print(f"âš ï¸ è·¯å¾„è´¨é‡ç‰¹å¾æå–å¤±è´¥: {e}")
            return torch.zeros_like(edge_attr)
    
    def _compute_constraint_features_safe(self, node_features, path_quality_info):
        """å®‰å…¨çš„çº¦æŸç‰¹å¾è®¡ç®—"""
        try:
            network_state = path_quality_info.get('network_state_vector', torch.zeros(8))
            
            if isinstance(network_state, np.ndarray):
                network_state = torch.tensor(network_state, device=node_features.device)
            elif isinstance(network_state, list):
                network_state = torch.tensor(network_state, device=node_features.device, dtype=torch.float32)
            
            constraint_features = network_state.unsqueeze(0).expand(node_features.size(0), -1)
            
            if constraint_features.size(-1) != self.edge_dim:
                if constraint_features.size(-1) < self.edge_dim:
                    padding = torch.zeros(constraint_features.size(0), 
                                        self.edge_dim - constraint_features.size(-1),
                                        device=constraint_features.device)
                    constraint_features = torch.cat([constraint_features, padding], dim=-1)
                else:
                    constraint_features = constraint_features[:, :self.edge_dim]
            
            return constraint_features
        except Exception as e:
            print(f"âš ï¸ çº¦æŸç‰¹å¾è®¡ç®—å¤±è´¥: {e}")
            return torch.zeros(node_features.size(0), self.edge_dim, device=node_features.device)


class EnhancedEdgeAwareGNN(nn.Module):
    """
    å¢å¼ºçš„Edge-Aware GNNç¼–ç å™¨ - ä¿®å¤ç‰ˆæœ¬
    """
    
    def __init__(self, node_dim=8, edge_dim=4, hidden_dim=128, output_dim=256, 
                 num_layers=6, vnf_context_dim=6):
        super(EnhancedEdgeAwareGNN, self).__init__()
        
        self.node_dim = node_dim
        self.edge_dim = edge_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        self.num_layers = num_layers
        self.vnf_context_dim = vnf_context_dim
        
        # èŠ‚ç‚¹å’Œè¾¹åµŒå…¥
        self.node_embedding = nn.Linear(node_dim, hidden_dim)
        self.edge_embedding = nn.Linear(edge_dim, hidden_dim)
        
        # ğŸ”§ ä¿®å¤ï¼šè¾¹æ³¨æ„åŠ›å±‚ä½¿ç”¨åŸå§‹è¾¹ç»´åº¦
        self.edge_attention = EdgeAttentionLayer(edge_dim, hidden_dim, vnf_context_dim)
        
        # è·¯å¾„è´¨é‡æ„ŸçŸ¥å·ç§¯å±‚
        self.conv_layers = nn.ModuleList()
        for i in range(num_layers):
            self.conv_layers.append(
                PathQualityAwareConv(hidden_dim, hidden_dim, hidden_dim, heads=4)
            )
        
        # å±‚å½’ä¸€åŒ–
        self.layer_norms = nn.ModuleList([
            nn.LayerNorm(hidden_dim) for _ in range(num_layers)
        ])
        
        # VNFä¸Šä¸‹æ–‡ç¼–ç å™¨
        self.vnf_context_encoder = nn.Sequential(
            nn.Linear(vnf_context_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim)
        )
        
        # å…¨å±€æ± åŒ–å’Œè¾“å‡º
        self.global_pool = Set2Set(hidden_dim, processing_steps=3)
        
        # å¤šå±‚è¾“å‡ºç½‘ç»œ
        self.output_net = nn.Sequential(
            nn.Linear(2 * hidden_dim + hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim // 2, output_dim),
            nn.ReLU()
        )
        
        # ç½‘ç»œçŠ¶æ€ç¼–ç å™¨
        self.network_state_encoder = nn.Linear(8, hidden_dim)
        
        print(f"ğŸš€ å¢å¼ºEdge-Aware GNNç¼–ç å™¨åˆå§‹åŒ–å®Œæˆ (ä¿®å¤ç‰ˆ)")
        print(f"   - èŠ‚ç‚¹ç»´åº¦: {node_dim} -> {hidden_dim}")
        print(f"   - è¾¹ç»´åº¦: {edge_dim} -> {hidden_dim}")
        print(f"   - å·ç§¯å±‚æ•°: {num_layers}")
        print(f"   - è¾“å‡ºç»´åº¦: {output_dim}")
        
    def forward(self, data):
        """
        å‰å‘ä¼ æ’­ - ä¿®å¤ç‰ˆæœ¬
        """
        # å¤„ç†è¾“å…¥æ•°æ®
        if isinstance(data, list):
            data = Batch.from_data_list(data)
        
        x = data.x.float()
        edge_index = data.edge_index
        edge_attr = data.edge_attr.float() if data.edge_attr is not None else None
        batch = data.batch if hasattr(data, 'batch') else None
        
        # æå–é¢å¤–ä¿¡æ¯
        vnf_context = getattr(data, 'vnf_context', None)
        network_state = getattr(data, 'network_state', None)
        enhanced_info = getattr(data, 'enhanced_info', None)
        
        # éªŒè¯è¾“å…¥ç»´åº¦
        try:
            self._validate_input_dimensions(x, edge_attr)
        except Exception as e:
            print(f"âš ï¸ ç»´åº¦éªŒè¯å¤±è´¥: {e}")
            # è‡ªåŠ¨ä¿®å¤ç»´åº¦
            x, edge_attr = self._auto_fix_dimensions(x, edge_attr)
        
        # 1. åŸºç¡€ç‰¹å¾åµŒå…¥
        x = self.node_embedding(x)
        original_edge_attr = edge_attr  # ä¿å­˜åŸå§‹è¾¹ç‰¹å¾
        
        if edge_attr is not None:
            edge_attr = self.edge_embedding(edge_attr)
        
        # 2. è¾¹æ³¨æ„åŠ›è®¡ç®— - ğŸ”§ ä½¿ç”¨åŸå§‹è¾¹ç‰¹å¾
        try:
            edge_attention, enhanced_edge_features, edge_importance = self.edge_attention(
                original_edge_attr, edge_index, vnf_context, network_state
            )
        except Exception as e:
            print(f"âš ï¸ è¾¹æ³¨æ„åŠ›è®¡ç®—å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤å€¼
            edge_attention = torch.ones(edge_attr.size(0), device=x.device) if edge_attr is not None else torch.ones(edge_index.size(1), device=x.device)
            enhanced_edge_features = edge_attr if edge_attr is not None else torch.zeros(edge_index.size(1), self.hidden_dim, device=x.device)
            edge_importance = torch.ones(enhanced_edge_features.size(0), 3, device=x.device) / 3.0
        
        # 3. å¤šå±‚å›¾å·ç§¯
        for i, (conv, norm) in enumerate(zip(self.conv_layers, self.layer_norms)):
            x_residual = x
            
            try:
                x = conv(x, edge_index, enhanced_edge_features, enhanced_info)
                x = norm(x)
                
                if x_residual.size() == x.size():
                    x = x + x_residual
                
                x = F.relu(x)
            except Exception as e:
                print(f"âš ï¸ ç¬¬{i}å±‚å·ç§¯å¤±è´¥: {e}")
                # è·³è¿‡è¿™ä¸€å±‚
                continue
        
        # 4. å…¨å±€æ± åŒ–
        try:
            if batch is not None:
                graph_embedding = self.global_pool(x, batch)
            else:
                batch_single = torch.zeros(x.size(0), dtype=torch.long, device=x.device)
                graph_embedding = self.global_pool(x, batch_single)
        except Exception as e:
            print(f"âš ï¸ å…¨å±€æ± åŒ–å¤±è´¥: {e}")
            # ä½¿ç”¨ç®€å•çš„å…¨å±€å¹³å‡æ± åŒ–
            graph_embedding = x.mean(dim=0, keepdim=True)
            graph_embedding = torch.cat([graph_embedding, graph_embedding], dim=-1)  # æ¨¡æ‹ŸSet2Setè¾“å‡º
        
        # 5. VNFä¸Šä¸‹æ–‡èåˆ
        try:
            if vnf_context is not None:
                vnf_embedding = self.vnf_context_encoder(vnf_context.float())
                if vnf_embedding.dim() == 1:
                    vnf_embedding = vnf_embedding.unsqueeze(0)
                
                if vnf_embedding.size(0) != graph_embedding.size(0):
                    vnf_embedding = vnf_embedding.expand(graph_embedding.size(0), -1)
                
                combined_embedding = torch.cat([graph_embedding, vnf_embedding], dim=-1)
            else:
                zero_context = torch.zeros(graph_embedding.size(0), self.hidden_dim, device=graph_embedding.device)
                combined_embedding = torch.cat([graph_embedding, zero_context], dim=-1)
        except Exception as e:
            print(f"âš ï¸ VNFä¸Šä¸‹æ–‡èåˆå¤±è´¥: {e}")
            # ä½¿ç”¨é›¶å¡«å……
            zero_context = torch.zeros(graph_embedding.size(0), self.hidden_dim, device=graph_embedding.device)
            combined_embedding = torch.cat([graph_embedding, zero_context], dim=-1)
        
        # 6. æœ€ç»ˆè¾“å‡º
        try:
            final_embedding = self.output_net(combined_embedding)
            final_embedding = F.normalize(final_embedding, p=2, dim=-1)
        except Exception as e:
            print(f"âš ï¸ æœ€ç»ˆè¾“å‡ºå¤±è´¥: {e}")
            # ä½¿ç”¨ç®€å•çš„çº¿æ€§å˜æ¢
            final_embedding = nn.Linear(combined_embedding.size(-1), self.output_dim).to(combined_embedding.device)(combined_embedding)
            final_embedding = F.normalize(final_embedding, p=2, dim=-1)
        
        return final_embedding
    
    def _validate_input_dimensions(self, x, edge_attr):
        """éªŒè¯è¾“å…¥ç»´åº¦"""
        if x.size(1) != self.node_dim:
            raise ValueError(f"èŠ‚ç‚¹ç‰¹å¾ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{self.node_dim}, å®é™…{x.size(1)}")
        
        if edge_attr is not None and edge_attr.size(1) != self.edge_dim:
            if self.edge_dim == 4 and edge_attr.size(1) == 2:
                # è‡ªåŠ¨æ‰©å±•2ç»´åˆ°4ç»´
                return  # å…è®¸è¿™ç§æƒ…å†µ
            else:
                raise ValueError(f"è¾¹ç‰¹å¾ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{self.edge_dim}, å®é™…{edge_attr.size(1)}")
    
    def _auto_fix_dimensions(self, x, edge_attr):
        """è‡ªåŠ¨ä¿®å¤ç»´åº¦é—®é¢˜"""
        # ä¿®å¤èŠ‚ç‚¹ç‰¹å¾ç»´åº¦
        if x.size(1) != self.node_dim:
            if x.size(1) < self.node_dim:
                padding = torch.zeros(x.size(0), self.node_dim - x.size(1), device=x.device)
                x = torch.cat([x, padding], dim=-1)
            else:
                x = x[:, :self.node_dim]
        
        # ä¿®å¤è¾¹ç‰¹å¾ç»´åº¦
        if edge_attr is not None and edge_attr.size(1) != self.edge_dim:
            if edge_attr.size(1) < self.edge_dim:
                padding = torch.zeros(edge_attr.size(0), self.edge_dim - edge_attr.size(1), device=edge_attr.device)
                edge_attr = torch.cat([edge_attr, padding], dim=-1)
            else:
                edge_attr = edge_attr[:, :self.edge_dim]
        
        return x, edge_attr
    
    def compute_edge_importance_map(self, data):
        """è®¡ç®—è¾¹é‡è¦æ€§æ˜ å°„ - å®‰å…¨ç‰ˆæœ¬"""
        try:
            with torch.no_grad():
                edge_index = data.edge_index
                edge_attr = data.edge_attr.float() if data.edge_attr is not None else None
                vnf_context = getattr(data, 'vnf_context', None)
                network_state = getattr(data, 'network_state', None)
                
                edge_attention, _, edge_importance = self.edge_attention(
                    edge_attr, edge_index, vnf_context, network_state
                )
                
                edge_importance_map = {}
                for i, (src, dst) in enumerate(edge_index.t()):
                    if i < len(edge_attention):
                        edge_key = (src.item(), dst.item())
                        edge_importance_map[edge_key] = {
                            'attention_weight': edge_attention[i].item(),
                            'importance_scores': edge_importance[i].cpu().numpy(),
                            'importance_level': edge_importance[i].argmax().item()
                        }
                
                return edge_importance_map
        except Exception as e:
            print(f"âš ï¸ è¾¹é‡è¦æ€§æ˜ å°„è®¡ç®—å¤±è´¥: {e}")
            return {}
    
    def get_vnf_adaptation_score(self, data):
        """è®¡ç®—VNFé€‚åº”æ€§è¯„åˆ† - å®‰å…¨ç‰ˆæœ¬"""
        try:
            with torch.no_grad():
                embedding = self.forward(data)
                edge_importance_map = self.compute_edge_importance_map(data)
                
                if edge_importance_map:
                    avg_attention = np.mean([info['attention_weight'] for info in edge_importance_map.values()])
                    high_importance_ratio = np.mean([
                        1 if info['importance_level'] == 2 else 0 
                        for info in edge_importance_map.values()
                    ])
                    adaptation_score = (avg_attention * 0.6 + high_importance_ratio * 0.4)
                else:
                    adaptation_score = 0.5  # é»˜è®¤ä¸­ç­‰é€‚åº”æ€§
                
                return float(adaptation_score)
        except Exception as e:
            print(f"âš ï¸ VNFé€‚åº”æ€§è¯„åˆ†è®¡ç®—å¤±è´¥: {e}")
            return 0.5


def create_enhanced_edge_aware_encoder_fixed(config: dict):
    """
    åˆ›å»ºä¿®å¤ç‰ˆå¢å¼ºEdge-Awareç¼–ç å™¨
    """
    gnn_config = config.get('gnn', {}).get('edge_aware', {})
    
    encoder = EnhancedEdgeAwareGNN(
        node_dim=config.get('dimensions', {}).get('node_feature_dim', 8),
        edge_dim=config.get('dimensions', {}).get('edge_feature_dim_full', 4),
        hidden_dim=gnn_config.get('hidden_dim', 128),
        output_dim=gnn_config.get('output_dim', 256),
        num_layers=gnn_config.get('layers', 6),
        vnf_context_dim=config.get('dimensions', {}).get('vnf_context_dim', 6)
    )
    
    print(f"âœ… ä¿®å¤ç‰ˆå¢å¼ºEdge-Awareç¼–ç å™¨åˆ›å»ºå®Œæˆ")
    return encoder