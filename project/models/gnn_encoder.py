# models/gnn_encoder.py - ä¿®å¤ç‰ˆï¼šç»Ÿä¸€8ç»´èŠ‚ç‚¹ç‰¹å¾

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, GATConv, Set2Set, global_mean_pool, global_add_pool
from torch_geometric.data import Data, Batch

class GNNEncoder(nn.Module):
    """
    ä¿®å¤ç‰ˆGNNç¼–ç å™¨ - è§£å†³ç»´åº¦ä¸ä¸€è‡´é—®é¢˜
    
    âœ… ä¿®å¤è¦ç‚¹ï¼š
    1. èŠ‚ç‚¹ç‰¹å¾ç»Ÿä¸€ä¸º8ç»´ï¼š[CPU, Memory, Storage, Network_Capacity, is_used, cpu_util, memory_util, vnf_count]
    2. è¾¹ç‰¹å¾æ”¯æŒ4ç»´(edge-aware)å’Œ2ç»´(baseline)ä¸¤ç§æ¨¡å¼
    3. ç¡®ä¿ä¸ç¯å¢ƒçŠ¶æ€ç”Ÿæˆé€»è¾‘å®Œå…¨ä¸€è‡´
    """
    
    def __init__(self, node_dim=8, edge_dim=4, hidden_dim=128, output_dim=256, num_layers=3):
        super(GNNEncoder, self).__init__()
        
        # âœ… å…³é”®ä¿®å¤ï¼šèŠ‚ç‚¹ç»´åº¦ç»Ÿä¸€ä¸º8
        self.node_dim = node_dim  # 8ç»´ï¼š4åŸºç¡€ç‰¹å¾ + 4çŠ¶æ€ç‰¹å¾
        self.edge_dim = edge_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        self.num_layers = num_layers
        
        # âœ… èŠ‚ç‚¹åµŒå…¥å±‚ï¼šå¤„ç†8ç»´è¾“å…¥
        self.node_embedding = nn.Linear(node_dim, hidden_dim)
        
        # âœ… è¾¹åµŒå…¥å±‚ï¼šæ”¯æŒå¯å˜ç»´åº¦
        self.edge_embedding = nn.Linear(edge_dim, hidden_dim)
        
        # GATå·ç§¯å±‚
        self.conv_layers = nn.ModuleList()
        for i in range(num_layers):
            self.conv_layers.append(
                GATConv(hidden_dim, hidden_dim, heads=4, concat=False, 
                       edge_dim=hidden_dim, dropout=0.1)
            )
        
        # å…¨å±€æ± åŒ–
        self.global_pool = Set2Set(hidden_dim, processing_steps=3)
        
        # è¾“å‡ºå±‚
        self.output_layers = nn.Sequential(
            nn.Linear(2 * hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, output_dim),
            nn.ReLU()
        )
        
        # æ‰¹å½’ä¸€åŒ–
        self.batch_norms = nn.ModuleList([
            nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)
        ])
        
        print(f"âœ… GNNç¼–ç å™¨åˆå§‹åŒ–: èŠ‚ç‚¹{node_dim}ç»´ -> éšè—{hidden_dim}ç»´ -> è¾“å‡º{output_dim}ç»´")
        
    def forward(self, data):
        """
        å‰å‘ä¼ æ’­
        
        è¾“å…¥:
        - data.x: [N, 8] èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µ
        - data.edge_index: [2, E] è¾¹ç´¢å¼•  
        - data.edge_attr: [E, edge_dim] è¾¹ç‰¹å¾çŸ©é˜µ
        """
        if isinstance(data, list):
            data = Batch.from_data_list(data)
        
        x = data.x.float()
        edge_index = data.edge_index
        edge_attr = data.edge_attr.float() if data.edge_attr is not None else None
        batch = data.batch if hasattr(data, 'batch') else None
        
        # âœ… ç»´åº¦éªŒè¯
        if x.size(1) != self.node_dim:
            raise ValueError(f"âŒ èŠ‚ç‚¹ç‰¹å¾ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{self.node_dim}ç»´ï¼Œå®é™…{x.size(1)}ç»´")
        
        if edge_attr is not None and edge_attr.size(1) != self.edge_dim:
            # âœ… æ”¯æŒç»´åº¦è‡ªé€‚åº”ï¼šå¦‚æœè¾¹ç‰¹å¾æ˜¯2ç»´ä½†æœŸæœ›4ç»´ï¼Œç”¨é›¶å¡«å……
            if self.edge_dim == 4 and edge_attr.size(1) == 2:
                padding = torch.zeros(edge_attr.size(0), 2, device=edge_attr.device)
                edge_attr = torch.cat([edge_attr, padding], dim=1)
                print(f"ğŸ”§ è¾¹ç‰¹å¾è‡ªåŠ¨æ‰©å±•: 2ç»´ -> 4ç»´")
            else:
                raise ValueError(f"âŒ è¾¹ç‰¹å¾ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{self.edge_dim}ç»´ï¼Œå®é™…{edge_attr.size(1)}ç»´")
        
        # ç‰¹å¾åµŒå…¥
        x = self.node_embedding(x)
        if edge_attr is not None:
            edge_attr = self.edge_embedding(edge_attr)
            edge_attr = F.normalize(edge_attr, p=2, dim=1)
        
        # GNNå·ç§¯
        for i, conv in enumerate(self.conv_layers):
            x_residual = x
            
            if edge_attr is not None:
                x = conv(x, edge_index, edge_attr=edge_attr)
            else:
                x = conv(x, edge_index)
            
            # æ‰¹å½’ä¸€åŒ–
            if batch is not None:
                x = self.batch_norms[i](x)
            else:
                if x.size(0) > 1:
                    x = self.batch_norms[i](x)
            
            x = F.relu(x)
            
            # æ®‹å·®è¿æ¥
            if x_residual.size() == x.size():
                x = x + x_residual
        
        # å…¨å±€æ± åŒ–
        if batch is not None:
            graph_embedding = self.global_pool(x, batch)
        else:
            batch_single = torch.zeros(x.size(0), dtype=torch.long, device=x.device)
            graph_embedding = self.global_pool(x, batch_single)
        
        # è¾“å‡ºå±‚
        graph_embedding = self.output_layers(graph_embedding)
        graph_embedding = F.normalize(graph_embedding, p=2, dim=1)
        
        return graph_embedding
    
    def encode_network_state(self, graph, node_features, edge_features):
        """
        ç¼–ç ç½‘ç»œçŠ¶æ€ä¸ºå›ºå®šç»´åº¦å‘é‡
        
        âœ… ä¿®å¤ç‰ˆï¼šç¡®ä¿è¾“å…¥ç‰¹å¾ç»´åº¦æ­£ç¡®
        """
        edge_list = list(graph.edges())
        edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()
        
        # âœ… ç¡®ä¿èŠ‚ç‚¹ç‰¹å¾æ˜¯8ç»´
        if node_features.shape[1] != 8:
            print(f"âš ï¸ èŠ‚ç‚¹ç‰¹å¾ç»´åº¦({node_features.shape[1]})ä¸æ˜¯8ï¼Œéœ€è¦åœ¨ç¯å¢ƒä¸­ä¿®å¤")
        
        x = torch.tensor(node_features, dtype=torch.float32)
        edge_attr = torch.tensor(edge_features, dtype=torch.float32)
        
        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)
        
        with torch.no_grad():
            encoded_state = self.forward(data)
        
        return encoded_state.squeeze(0)
    
    def get_edge_importance(self, data):
        """è®¡ç®—è¾¹çš„é‡è¦æ€§æƒé‡"""
        if hasattr(data, 'edge_attr') and data.edge_attr is not None:
            return torch.ones(data.edge_attr.size(0))
        else:
            return torch.ones(data.edge_index.size(1))

class EdgeAwareGNNEncoder(GNNEncoder):
    """
    è¾¹æ„ŸçŸ¥GNNç¼–ç å™¨ - ä¿®å¤ç‰ˆ
    
    âœ… å¢å¼ºåŠŸèƒ½ï¼š
    1. VNFéœ€æ±‚ä¸Šä¸‹æ–‡ç¼–ç 
    2. è¾¹é‡è¦æ€§è¯„ä¼°
    3. åŠ¨æ€ç‰¹å¾èåˆ
    """
    
    def __init__(self, node_dim=8, edge_dim=4, hidden_dim=128, output_dim=256, num_layers=3):
        super(EdgeAwareGNNEncoder, self).__init__(node_dim, edge_dim, hidden_dim, output_dim, num_layers)
        
        # âœ… VNFéœ€æ±‚ç¼–ç å™¨ï¼šå¤„ç†6ç»´VNFä¸Šä¸‹æ–‡
        self.vnf_requirement_encoder = nn.Linear(6, hidden_dim)  # [cpu, memory, bandwidth/100, vnf_type/3, progress, remaining]
        
        # è¾¹é‡è¦æ€§ç½‘ç»œ
        self.edge_importance_net = nn.Sequential(
            nn.Linear(edge_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 1),
            nn.Sigmoid()
        )
        
        # ç‰¹å¾èåˆç½‘ç»œ
        self.feature_fusion = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1)
        )
        
        print(f"âœ… EdgeAwareç¼–ç å™¨åˆå§‹åŒ–: VNFä¸Šä¸‹æ–‡æ”¯æŒ")
        
    def forward_with_vnf_context(self, data, vnf_context=None):
        """
        å¸¦VNFä¸Šä¸‹æ–‡çš„å‰å‘ä¼ æ’­
        
        å‚æ•°:
        - data: å›¾æ•°æ®
        - vnf_context: [6] VNFéœ€æ±‚å‘é‡
        """
        # åŸºç¡€å›¾ç¼–ç 
        graph_embedding = self.forward(data)
        
        # VNFä¸Šä¸‹æ–‡èåˆ
        if vnf_context is not None:
            if isinstance(vnf_context, torch.Tensor):
                vnf_tensor = vnf_context.float()
            else:
                vnf_tensor = torch.tensor(vnf_context, dtype=torch.float32)
            
            if vnf_tensor.dim() == 1:
                vnf_tensor = vnf_tensor.unsqueeze(0)
            
            # âœ… VNFä¸Šä¸‹æ–‡ç¼–ç 
            vnf_embedding = self.vnf_requirement_encoder(vnf_tensor)
            
            # ç‰¹å¾èåˆ
            if graph_embedding.size(0) == vnf_embedding.size(0):
                fused_features = torch.cat([graph_embedding, vnf_embedding], dim=1)
                enhanced_embedding = self.feature_fusion(fused_features)
            else:
                # å¹¿æ’­å¤„ç†
                enhanced_embedding = graph_embedding + 0.3 * vnf_embedding.mean(dim=0, keepdim=True)
            
            return enhanced_embedding
        else:
            return graph_embedding
    
    def compute_edge_attention(self, data):
        """è®¡ç®—è¾¹æ³¨æ„åŠ›æƒé‡"""
        if hasattr(data, 'edge_attr') and data.edge_attr is not None:
            attention_weights = self.edge_importance_net(data.edge_attr.float())
            return attention_weights.squeeze(-1)
        else:
            return torch.ones(data.edge_index.size(1), device=data.edge_index.device)

def create_gnn_encoder(config: dict, mode: str = 'edge_aware'):
    """
    åˆ›å»ºGNNç¼–ç å™¨çš„å·¥å‚å‡½æ•°
    
    å‚æ•°:
    - config: é…ç½®å­—å…¸
    - mode: 'edge_aware' æˆ– 'baseline'
    """
    if mode == 'edge_aware':
        gnn_config = config.get('gnn', {}).get('edge_aware', {})
        encoder = EdgeAwareGNNEncoder(
            node_dim=8,  # âœ… ç»Ÿä¸€ä¸º8ç»´
            edge_dim=gnn_config.get('edge_dim', 4),
            hidden_dim=gnn_config.get('hidden_dim', 128),
            output_dim=gnn_config.get('output_dim', 256),
            num_layers=gnn_config.get('layers', 6)
        )
    else:  # baseline
        gnn_config = config.get('gnn', {}).get('baseline', {})
        encoder = GNNEncoder(
            node_dim=8,  # âœ… ç»Ÿä¸€ä¸º8ç»´
            edge_dim=gnn_config.get('edge_dim', 2),
            hidden_dim=gnn_config.get('hidden_dim', 64),
            output_dim=gnn_config.get('output_dim', 256),
            num_layers=gnn_config.get('layers', 4)
        )
    
    print(f"âœ… åˆ›å»º{mode}æ¨¡å¼GNNç¼–ç å™¨")
    return encoder

def test_gnn_encoder_fixed():
    """
    æµ‹è¯•ä¿®å¤ç‰ˆGNNç¼–ç å™¨
    """
    print("ğŸ§ª æµ‹è¯•ä¿®å¤ç‰ˆGNNç¼–ç å™¨...")
    print("=" * 50)
    
    # æµ‹è¯•å‚æ•°
    num_nodes = 10
    num_edges = 20
    node_dim = 8  # âœ… ä¿®å¤ï¼šä½¿ç”¨8ç»´èŠ‚ç‚¹ç‰¹å¾
    edge_dim_full = 4  # edge-awareæ¨¡å¼
    edge_dim_baseline = 2  # baselineæ¨¡å¼
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    x = torch.randn(num_nodes, node_dim)
    edge_index = torch.randint(0, num_nodes, (2, num_edges))
    edge_attr_full = torch.randn(num_edges, edge_dim_full)
    edge_attr_baseline = torch.randn(num_edges, edge_dim_baseline)
    
    # æµ‹è¯•1: EdgeAwareæ¨¡å¼
    print("\n1. æµ‹è¯•EdgeAwareæ¨¡å¼:")
    data_full = Data(x=x, edge_index=edge_index, edge_attr=edge_attr_full)
    encoder_full = EdgeAwareGNNEncoder(node_dim=node_dim, edge_dim=edge_dim_full)
    
    with torch.no_grad():
        output_full = encoder_full(data_full)
        print(f"   âœ… è¾“å…¥: {num_nodes}èŠ‚ç‚¹Ã—{node_dim}ç»´, {num_edges}è¾¹Ã—{edge_dim_full}ç»´")
        print(f"   âœ… è¾“å‡º: {output_full.shape}")
    
    # æµ‹è¯•2: Baselineæ¨¡å¼
    print("\n2. æµ‹è¯•Baselineæ¨¡å¼:")
    data_baseline = Data(x=x, edge_index=edge_index, edge_attr=edge_attr_baseline)
    encoder_baseline = GNNEncoder(node_dim=node_dim, edge_dim=edge_dim_baseline)
    
    with torch.no_grad():
        output_baseline = encoder_baseline(data_baseline)
        print(f"   âœ… è¾“å…¥: {num_nodes}èŠ‚ç‚¹Ã—{node_dim}ç»´, {num_edges}è¾¹Ã—{edge_dim_baseline}ç»´")
        print(f"   âœ… è¾“å‡º: {output_baseline.shape}")
    
    # æµ‹è¯•3: VNFä¸Šä¸‹æ–‡
    print("\n3. æµ‹è¯•VNFä¸Šä¸‹æ–‡èåˆ:")
    vnf_context = torch.tensor([0.05, 0.03, 0.04, 0.33, 0.5, 0.5])  # 6ç»´VNFä¸Šä¸‹æ–‡
    
    with torch.no_grad():
        output_with_context = encoder_full.forward_with_vnf_context(data_full, vnf_context)
        print(f"   âœ… VNFä¸Šä¸‹æ–‡: {vnf_context.shape}")
        print(f"   âœ… èåˆè¾“å‡º: {output_with_context.shape}")
    
    # æµ‹è¯•4: ç»´åº¦ä¸€è‡´æ€§éªŒè¯
    print("\n4. ç»´åº¦ä¸€è‡´æ€§éªŒè¯:")
    assert output_full.shape == output_baseline.shape == output_with_context.shape, "è¾“å‡ºç»´åº¦ä¸ä¸€è‡´!"
    print(f"   âœ… æ‰€æœ‰æ¨¡å¼è¾“å‡ºç»´åº¦ä¸€è‡´: {output_full.shape}")
    
    # æµ‹è¯•5: è¾¹ç‰¹å¾è‡ªé€‚åº”
    print("\n5. æµ‹è¯•è¾¹ç‰¹å¾è‡ªé€‚åº”:")
    data_adaptive = Data(x=x, edge_index=edge_index, edge_attr=edge_attr_baseline)
    encoder_adaptive = GNNEncoder(node_dim=node_dim, edge_dim=edge_dim_full)  # æœŸæœ›4ç»´ä½†è¾“å…¥2ç»´
    
    with torch.no_grad():
        output_adaptive = encoder_adaptive(data_adaptive)
        print(f"   âœ… è‡ªé€‚åº”å¤„ç†: 2ç»´è¾¹ç‰¹å¾ -> 4ç»´ç¼–ç å™¨")
        print(f"   âœ… è¾“å‡º: {output_adaptive.shape}")
    
    print(f"\nğŸ‰ GNNç¼–ç å™¨ä¿®å¤ç‰ˆæµ‹è¯•é€šè¿‡!")
    print(f"   - æ”¯æŒ8ç»´èŠ‚ç‚¹ç‰¹å¾ âœ…")
    print(f"   - æ”¯æŒ4ç»´/2ç»´è¾¹ç‰¹å¾ âœ…") 
    print(f"   - VNFä¸Šä¸‹æ–‡èåˆ âœ…")
    print(f"   - ç»´åº¦è‡ªé€‚åº” âœ…")
    print(f"   - è¾“å‡ºç»´åº¦å›ºå®š âœ…")

if __name__ == "__main__":
    test_gnn_encoder_fixed()