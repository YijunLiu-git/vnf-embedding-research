# models/enhanced_gnn_encoder.py - å¢å¼ºçš„Edge-Aware GNNç¼–ç å™¨

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, GATConv, Set2Set, global_mean_pool, global_add_pool
from torch_geometric.data import Data, Batch
import numpy as np

class EdgeAttentionLayer(nn.Module):
    """
    è¾¹æ³¨æ„åŠ›å±‚ - Edge-Awareçš„æ ¸å¿ƒåˆ›æ–°
    
    åŠŸèƒ½ï¼š
    1. è®¡ç®—è¾¹çš„é‡è¦æ€§æƒé‡
    2. åŸºäºVNFéœ€æ±‚åŠ¨æ€è°ƒæ•´è¾¹æƒé‡
    3. èåˆè¾¹ç‰¹å¾å’Œå…¨å±€ç½‘ç»œçŠ¶æ€
    """
    
    def __init__(self, edge_dim, hidden_dim, vnf_context_dim=6):
        super(EdgeAttentionLayer, self).__init__()
        
        self.edge_dim = edge_dim
        self.hidden_dim = hidden_dim
        self.vnf_context_dim = vnf_context_dim
        
        # è¾¹ç‰¹å¾æŠ•å½±
        self.edge_proj = nn.Linear(edge_dim, hidden_dim)
        
        # VNFéœ€æ±‚ç¼–ç å™¨
        self.vnf_encoder = nn.Linear(vnf_context_dim, hidden_dim)
        
        # æ³¨æ„åŠ›è®¡ç®—ç½‘ç»œ
        self.attention_net = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 1),
            nn.Sigmoid()
        )
        
        # è¾¹é‡è¦æ€§åˆ†ç±»å™¨
        self.importance_classifier = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 3),  # 3ä¸ªé‡è¦æ€§ç­‰çº§ï¼šä½ã€ä¸­ã€é«˜
            nn.Softmax(dim=-1)
        )
        
        # å…¨å±€ç½‘ç»œçŠ¶æ€æ„ŸçŸ¥
        self.global_attention = nn.MultiheadAttention(
            embed_dim=hidden_dim,
            num_heads=4,
            dropout=0.1,
            batch_first=True
        )
        
    def forward(self, edge_attr, edge_index, vnf_context=None, network_state=None):
        """
        è®¡ç®—è¾¹æ³¨æ„åŠ›æƒé‡
        
        Args:
            edge_attr: [E, edge_dim] è¾¹ç‰¹å¾
            edge_index: [2, E] è¾¹ç´¢å¼•
            vnf_context: [vnf_context_dim] VNFéœ€æ±‚ä¸Šä¸‹æ–‡
            network_state: [network_state_dim] å…¨å±€ç½‘ç»œçŠ¶æ€
            
        Returns:
            edge_attention: [E] è¾¹æ³¨æ„åŠ›æƒé‡
            edge_features: [E, hidden_dim] å¢å¼ºè¾¹ç‰¹å¾
            edge_importance: [E, 3] è¾¹é‡è¦æ€§åˆ†å¸ƒ
        """
        # 1. è¾¹ç‰¹å¾ç¼–ç 
        edge_features = self.edge_proj(edge_attr)  # [E, hidden_dim]
        
        # 2. VNFä¸Šä¸‹æ–‡èåˆ
        if vnf_context is not None:
            if vnf_context.dim() == 1:
                vnf_context = vnf_context.unsqueeze(0)
            vnf_embedding = self.vnf_encoder(vnf_context)  # [1, hidden_dim]
            
            # å¹¿æ’­VNFåµŒå…¥åˆ°æ‰€æœ‰è¾¹
            vnf_broadcast = vnf_embedding.expand(edge_features.size(0), -1)  # [E, hidden_dim]
            
            # èåˆè¾¹ç‰¹å¾å’ŒVNFéœ€æ±‚
            combined_features = torch.cat([edge_features, vnf_broadcast], dim=-1)  # [E, hidden_dim*2]
            
            # è®¡ç®—æ³¨æ„åŠ›æƒé‡
            edge_attention = self.attention_net(combined_features).squeeze(-1)  # [E]
        else:
            # é»˜è®¤å‡åŒ€æ³¨æ„åŠ›
            edge_attention = torch.ones(edge_features.size(0), device=edge_features.device)
        
        # 3. å…¨å±€ç½‘ç»œçŠ¶æ€æ„ŸçŸ¥
        if network_state is not None:
            # ä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›æ•´åˆå…¨å±€çŠ¶æ€
            edge_features_expanded = edge_features.unsqueeze(0)  # [1, E, hidden_dim]
            network_state_expanded = network_state.unsqueeze(0).unsqueeze(0)  # [1, 1, hidden_dim]
            
            attended_features, _ = self.global_attention(
                edge_features_expanded, 
                network_state_expanded, 
                network_state_expanded
            )
            edge_features = attended_features.squeeze(0)  # [E, hidden_dim]
        
        # 4. è¾¹é‡è¦æ€§åˆ†ç±»
        edge_importance = self.importance_classifier(edge_features)  # [E, 3]
        
        # 5. åº”ç”¨æ³¨æ„åŠ›æƒé‡
        weighted_edge_features = edge_features * edge_attention.unsqueeze(-1)
        
        return edge_attention, weighted_edge_features, edge_importance


class PathQualityAwareConv(nn.Module):
    """
    è·¯å¾„è´¨é‡æ„ŸçŸ¥å·ç§¯å±‚
    
    åŠŸèƒ½ï¼š
    1. æ•´åˆè·¯å¾„è´¨é‡ä¿¡æ¯
    2. åŠ¨æ€è°ƒæ•´æ¶ˆæ¯ä¼ æ’­æƒé‡
    3. è€ƒè™‘ç«¯åˆ°ç«¯è·¯å¾„çº¦æŸ
    """
    
    def __init__(self, in_dim, out_dim, edge_dim, heads=4):
        super(PathQualityAwareConv, self).__init__()
        
        self.in_dim = in_dim
        self.out_dim = out_dim
        self.edge_dim = edge_dim
        self.heads = heads
        
        # åŸºç¡€GATå±‚
        self.gat = GATConv(
            in_channels=in_dim,
            out_channels=out_dim,
            heads=heads,
            concat=False,
            edge_dim=edge_dim,
            dropout=0.1
        )
        
        # è·¯å¾„è´¨é‡ç¼–ç å™¨
        self.path_quality_encoder = nn.Sequential(
            nn.Linear(4, edge_dim // 2),  # è¾“å…¥ï¼š[bandwidth, latency, jitter, loss]
            nn.ReLU(),
            nn.Linear(edge_dim // 2, edge_dim)
        )
        
        # è·¯å¾„çº¦æŸæ„ŸçŸ¥å±‚
        self.constraint_awareness = nn.Sequential(
            nn.Linear(out_dim + edge_dim, out_dim),
            nn.ReLU(),
            nn.Dropout(0.1)
        )
        
    def forward(self, x, edge_index, edge_attr, path_quality_info=None):
        """
        è·¯å¾„è´¨é‡æ„ŸçŸ¥çš„å›¾å·ç§¯
        
        Args:
            x: [N, in_dim] èŠ‚ç‚¹ç‰¹å¾
            edge_index: [2, E] è¾¹ç´¢å¼•
            edge_attr: [E, edge_dim] è¾¹ç‰¹å¾
            path_quality_info: è·¯å¾„è´¨é‡ä¿¡æ¯å­—å…¸
            
        Returns:
            x_out: [N, out_dim] æ›´æ–°åçš„èŠ‚ç‚¹ç‰¹å¾
        """
        # 1. åŸºç¡€å›¾å·ç§¯
        x_conv = self.gat(x, edge_index, edge_attr)
        
        # 2. è·¯å¾„è´¨é‡ä¿¡æ¯èåˆ
        if path_quality_info is not None:
            # æå–è·¯å¾„è´¨é‡ç‰¹å¾
            quality_features = self._extract_path_quality_features(
                edge_index, edge_attr, path_quality_info
            )
            
            # å¢å¼ºè¾¹ç‰¹å¾
            enhanced_edge_attr = edge_attr + quality_features
            
            # é‡æ–°è®¡ç®—å·ç§¯
            x_conv = self.gat(x, edge_index, enhanced_edge_attr)
        
        # 3. çº¦æŸæ„ŸçŸ¥å¤„ç†
        if path_quality_info is not None:
            # ç»“åˆçº¦æŸä¿¡æ¯
            constraint_features = self._compute_constraint_features(x_conv, path_quality_info)
            x_out = self.constraint_awareness(
                torch.cat([x_conv, constraint_features], dim=-1)
            )
        else:
            x_out = x_conv
        
        return x_out
    
    def _extract_path_quality_features(self, edge_index, edge_attr, path_quality_info):
        """æå–è·¯å¾„è´¨é‡ç‰¹å¾"""
        # ä»è·¯å¾„è´¨é‡çŸ©é˜µä¸­æå–ç›¸å…³ä¿¡æ¯
        quality_matrix = path_quality_info.get('path_quality_matrix', {})
        
        # æ„å»ºè´¨é‡ç‰¹å¾å‘é‡
        quality_features = torch.zeros_like(edge_attr)
        
        for i, (src, dst) in enumerate(edge_index.t()):
            src_idx, dst_idx = src.item(), dst.item()
            path_info = quality_matrix.get((src_idx, dst_idx), {})
            
            if path_info:
                # æå–è´¨é‡æŒ‡æ ‡
                bandwidth = path_info.get('bandwidth', 0.0)
                latency = path_info.get('latency', 0.0)
                jitter = path_info.get('jitter', 0.0)
                loss = path_info.get('packet_loss', 0.0)
                
                # ç¼–ç è´¨é‡ç‰¹å¾
                quality_vec = torch.tensor([bandwidth/100, latency/100, jitter*100, loss*100], 
                                         device=edge_attr.device)
                quality_encoded = self.path_quality_encoder(quality_vec)
                quality_features[i] = quality_encoded
        
        return quality_features
    
    def _compute_constraint_features(self, node_features, path_quality_info):
        """è®¡ç®—çº¦æŸç‰¹å¾"""
        # ç®€åŒ–å®ç°ï¼šåŸºäºç½‘ç»œçŠ¶æ€è®¡ç®—çº¦æŸç‰¹å¾
        network_state = path_quality_info.get('network_state_vector', torch.zeros(8))
        
        if isinstance(network_state, np.ndarray):
            network_state = torch.tensor(network_state, device=node_features.device)
        
        # å¹¿æ’­ç½‘ç»œçŠ¶æ€åˆ°æ‰€æœ‰èŠ‚ç‚¹
        constraint_features = network_state.unsqueeze(0).expand(
            node_features.size(0), -1
        )
        
        # ç¡®ä¿ç»´åº¦åŒ¹é…
        if constraint_features.size(-1) != self.edge_dim:
            constraint_features = F.adaptive_avg_pool1d(
                constraint_features.unsqueeze(1), self.edge_dim
            ).squeeze(1)
        
        return constraint_features


class EnhancedEdgeAwareGNN(nn.Module):
    """
    å¢å¼ºçš„Edge-Aware GNNç¼–ç å™¨
    
    æ ¸å¿ƒåˆ›æ–°ï¼š
    1. è¾¹æ³¨æ„åŠ›æœºåˆ¶
    2. è·¯å¾„è´¨é‡æ„ŸçŸ¥å·ç§¯
    3. VNFéœ€æ±‚é€‚åº”æ€§ç¼–ç 
    4. åŠ¨æ€ç½‘ç»œçŠ¶æ€æ›´æ–°
    """
    
    def __init__(self, node_dim=8, edge_dim=4, hidden_dim=128, output_dim=256, 
                 num_layers=6, vnf_context_dim=6):
        super(EnhancedEdgeAwareGNN, self).__init__()
        
        self.node_dim = node_dim
        self.edge_dim = edge_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        self.num_layers = num_layers
        self.vnf_context_dim = vnf_context_dim
        
        # èŠ‚ç‚¹å’Œè¾¹åµŒå…¥
        self.node_embedding = nn.Linear(node_dim, hidden_dim)
        self.edge_embedding = nn.Linear(edge_dim, hidden_dim)
        
        # è¾¹æ³¨æ„åŠ›å±‚
        self.edge_attention = EdgeAttentionLayer(edge_dim, hidden_dim, vnf_context_dim)
        
        # è·¯å¾„è´¨é‡æ„ŸçŸ¥å·ç§¯å±‚
        self.conv_layers = nn.ModuleList()
        for i in range(num_layers):
            self.conv_layers.append(
                PathQualityAwareConv(hidden_dim, hidden_dim, hidden_dim, heads=4)
            )
        
        # å±‚å½’ä¸€åŒ–
        self.layer_norms = nn.ModuleList([
            nn.LayerNorm(hidden_dim) for _ in range(num_layers)
        ])
        
        # VNFä¸Šä¸‹æ–‡ç¼–ç å™¨
        self.vnf_context_encoder = nn.Sequential(
            nn.Linear(vnf_context_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim)
        )
        
        # å…¨å±€æ± åŒ–å’Œè¾“å‡º
        self.global_pool = Set2Set(hidden_dim, processing_steps=3)
        
        # å¤šå±‚è¾“å‡ºç½‘ç»œ
        self.output_net = nn.Sequential(
            nn.Linear(2 * hidden_dim + hidden_dim, hidden_dim),  # +hidden_dim for VNF context
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim // 2, output_dim),
            nn.ReLU()
        )
        
        # ç½‘ç»œçŠ¶æ€ç¼–ç å™¨
        self.network_state_encoder = nn.Linear(8, hidden_dim)  # 8ç»´ç½‘ç»œçŠ¶æ€å‘é‡
        
        print(f"ğŸš€ å¢å¼ºEdge-Aware GNNç¼–ç å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   - èŠ‚ç‚¹ç»´åº¦: {node_dim} -> {hidden_dim}")
        print(f"   - è¾¹ç»´åº¦: {edge_dim} -> {hidden_dim}")
        print(f"   - å·ç§¯å±‚æ•°: {num_layers}")
        print(f"   - è¾“å‡ºç»´åº¦: {output_dim}")
        print(f"   - æ ¸å¿ƒåˆ›æ–°: è¾¹æ³¨æ„åŠ› + è·¯å¾„è´¨é‡æ„ŸçŸ¥")
        
    def forward(self, data):
        """
        å‰å‘ä¼ æ’­ - å®Œæ•´çš„Edge-Awareå¤„ç†æµç¨‹
        
        Args:
            data: PyGæ•°æ®å¯¹è±¡ï¼ŒåŒ…å«ï¼š
                - x: [N, node_dim] èŠ‚ç‚¹ç‰¹å¾
                - edge_index: [2, E] è¾¹ç´¢å¼•
                - edge_attr: [E, edge_dim] è¾¹ç‰¹å¾
                - vnf_context: [vnf_context_dim] VNFä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
                - network_state: [8] ç½‘ç»œçŠ¶æ€å‘é‡ï¼ˆå¯é€‰ï¼‰
                - enhanced_info: å¢å¼ºçŠ¶æ€ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
                
        Returns:
            graph_embedding: [batch_size, output_dim] å›¾åµŒå…¥
        """
        # å¤„ç†è¾“å…¥æ•°æ®
        if isinstance(data, list):
            data = Batch.from_data_list(data)
        
        x = data.x.float()
        edge_index = data.edge_index
        edge_attr = data.edge_attr.float() if data.edge_attr is not None else None
        batch = data.batch if hasattr(data, 'batch') else None
        
        # æå–é¢å¤–ä¿¡æ¯
        vnf_context = getattr(data, 'vnf_context', None)
        network_state = getattr(data, 'network_state', None)
        enhanced_info = getattr(data, 'enhanced_info', None)
        
        # éªŒè¯è¾“å…¥ç»´åº¦
        self._validate_input_dimensions(x, edge_attr)
        
        # 1. åŸºç¡€ç‰¹å¾åµŒå…¥
        x = self.node_embedding(x)
        if edge_attr is not None:
            edge_attr = self.edge_embedding(edge_attr)
        
        # 2. è¾¹æ³¨æ„åŠ›è®¡ç®—
        edge_attention, enhanced_edge_features, edge_importance = self.edge_attention(
            edge_attr, edge_index, vnf_context, network_state
        )
        
        # 3. å¤šå±‚å›¾å·ç§¯ï¼ˆè·¯å¾„è´¨é‡æ„ŸçŸ¥ï¼‰
        for i, (conv, norm) in enumerate(zip(self.conv_layers, self.layer_norms)):
            x_residual = x
            
            # è·¯å¾„è´¨é‡æ„ŸçŸ¥å·ç§¯
            x = conv(x, edge_index, enhanced_edge_features, enhanced_info)
            
            # å±‚å½’ä¸€åŒ–
            x = norm(x)
            
            # æ®‹å·®è¿æ¥
            if x_residual.size() == x.size():
                x = x + x_residual
            
            # æ¿€æ´»å‡½æ•°
            x = F.relu(x)
        
        # 4. å…¨å±€æ± åŒ–
        if batch is not None:
            graph_embedding = self.global_pool(x, batch)
        else:
            batch_single = torch.zeros(x.size(0), dtype=torch.long, device=x.device)
            graph_embedding = self.global_pool(x, batch_single)
        
        # 5. VNFä¸Šä¸‹æ–‡èåˆ
        if vnf_context is not None:
            vnf_embedding = self.vnf_context_encoder(vnf_context.float())
            if vnf_embedding.dim() == 1:
                vnf_embedding = vnf_embedding.unsqueeze(0)
            
            # ç¡®ä¿batchç»´åº¦åŒ¹é…
            if vnf_embedding.size(0) != graph_embedding.size(0):
                vnf_embedding = vnf_embedding.expand(graph_embedding.size(0), -1)
            
            # èåˆå›¾åµŒå…¥å’ŒVNFä¸Šä¸‹æ–‡
            combined_embedding = torch.cat([graph_embedding, vnf_embedding], dim=-1)
        else:
            # è¡¥é›¶VNFä¸Šä¸‹æ–‡
            zero_context = torch.zeros(graph_embedding.size(0), self.hidden_dim, 
                                     device=graph_embedding.device)
            combined_embedding = torch.cat([graph_embedding, zero_context], dim=-1)
        
        # 6. æœ€ç»ˆè¾“å‡º
        final_embedding = self.output_net(combined_embedding)
        final_embedding = F.normalize(final_embedding, p=2, dim=-1)
        
        return final_embedding
    
    def _validate_input_dimensions(self, x, edge_attr):
        """éªŒè¯è¾“å…¥ç»´åº¦"""
        if x.size(1) != self.node_dim:
            raise ValueError(f"èŠ‚ç‚¹ç‰¹å¾ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{self.node_dim}, å®é™…{x.size(1)}")
        
        if edge_attr is not None and edge_attr.size(1) != self.edge_dim:
            if self.edge_dim == 4 and edge_attr.size(1) == 2:
                # è‡ªåŠ¨æ‰©å±•2ç»´åˆ°4ç»´
                padding = torch.zeros(edge_attr.size(0), 2, device=edge_attr.device)
                edge_attr = torch.cat([edge_attr, padding], dim=1)
                print("ğŸ”§ è¾¹ç‰¹å¾è‡ªåŠ¨æ‰©å±•: 2ç»´ -> 4ç»´")
            else:
                raise ValueError(f"è¾¹ç‰¹å¾ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{self.edge_dim}, å®é™…{edge_attr.size(1)}")
    
    def compute_edge_importance_map(self, data):
        """
        è®¡ç®—è¾¹é‡è¦æ€§æ˜ å°„ - ç”¨äºåˆ†æå’Œå¯è§†åŒ–
        
        Returns:
            edge_importance_map: è¾¹é‡è¦æ€§åˆ†å¸ƒå­—å…¸
        """
        with torch.no_grad():
            # æå–åŸºç¡€æ•°æ®
            edge_index = data.edge_index
            edge_attr = data.edge_attr.float() if data.edge_attr is not None else None
            vnf_context = getattr(data, 'vnf_context', None)
            network_state = getattr(data, 'network_state', None)
            
            # åµŒå…¥è¾¹ç‰¹å¾
            if edge_attr is not None:
                edge_attr = self.edge_embedding(edge_attr)
            
            # è®¡ç®—è¾¹æ³¨æ„åŠ›
            edge_attention, _, edge_importance = self.edge_attention(
                edge_attr, edge_index, vnf_context, network_state
            )
            
            # æ„å»ºé‡è¦æ€§æ˜ å°„
            edge_importance_map = {}
            for i, (src, dst) in enumerate(edge_index.t()):
                edge_key = (src.item(), dst.item())
                edge_importance_map[edge_key] = {
                    'attention_weight': edge_attention[i].item(),
                    'importance_scores': edge_importance[i].cpu().numpy(),
                    'importance_level': edge_importance[i].argmax().item()  # 0:ä½, 1:ä¸­, 2:é«˜
                }
            
            return edge_importance_map
    
    def get_vnf_adaptation_score(self, data):
        """
        è®¡ç®—VNFé€‚åº”æ€§è¯„åˆ† - è¡¡é‡ç½‘ç»œå¯¹å½“å‰VNFéœ€æ±‚çš„é€‚åº”ç¨‹åº¦
        
        Returns:
            adaptation_score: é€‚åº”æ€§è¯„åˆ† (0-1)
        """
        with torch.no_grad():
            # å‰å‘ä¼ æ’­è·å–åµŒå…¥
            embedding = self.forward(data)
            
            # è®¡ç®—è¾¹é‡è¦æ€§
            edge_importance_map = self.compute_edge_importance_map(data)
            
            # è¯„ä¼°æŒ‡æ ‡
            avg_attention = np.mean([info['attention_weight'] for info in edge_importance_map.values()])
            high_importance_ratio = np.mean([
                1 if info['importance_level'] == 2 else 0 
                for info in edge_importance_map.values()
            ])
            
            # ç»¼åˆè¯„åˆ†
            adaptation_score = (avg_attention * 0.6 + high_importance_ratio * 0.4)
            
            return float(adaptation_score)


def create_enhanced_edge_aware_encoder(config: dict):
    """
    åˆ›å»ºå¢å¼ºEdge-Awareç¼–ç å™¨çš„å·¥å‚å‡½æ•°
    
    Args:
        config: é…ç½®å­—å…¸
        
    Returns:
        encoder: å¢å¼ºçš„Edge-Aware GNNç¼–ç å™¨
    """
    gnn_config = config.get('gnn', {}).get('edge_aware', {})
    
    encoder = EnhancedEdgeAwareGNN(
        node_dim=config.get('dimensions', {}).get('node_feature_dim', 8),
        edge_dim=config.get('dimensions', {}).get('edge_feature_dim_full', 4),
        hidden_dim=gnn_config.get('hidden_dim', 128),
        output_dim=gnn_config.get('output_dim', 256),
        num_layers=gnn_config.get('layers', 6),
        vnf_context_dim=config.get('dimensions', {}).get('vnf_context_dim', 6)
    )
    
    print(f"âœ… å¢å¼ºEdge-Awareç¼–ç å™¨åˆ›å»ºå®Œæˆ")
    return encoder


# æµ‹è¯•å‡½æ•°
def test_enhanced_gnn():
    """æµ‹è¯•å¢å¼ºGNNç¼–ç å™¨"""
    print("ğŸ§ª æµ‹è¯•å¢å¼ºEdge-Aware GNNç¼–ç å™¨...")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    num_nodes = 20
    num_edges = 50
    batch_size = 2
    
    # èŠ‚ç‚¹ç‰¹å¾ [N, 8]
    x = torch.randn(num_nodes, 8)
    
    # è¾¹ç´¢å¼•å’Œç‰¹å¾
    edge_index = torch.randint(0, num_nodes, (2, num_edges))
    edge_attr = torch.randn(num_edges, 4)
    
    # VNFä¸Šä¸‹æ–‡ [6]
    vnf_context = torch.tensor([0.05, 0.03, 0.04, 0.33, 0.5, 0.5])
    
    # ç½‘ç»œçŠ¶æ€ [8]
    network_state = torch.randn(8)
    
    # æ„å»ºæ•°æ®å¯¹è±¡
    data = Data(
        x=x, 
        edge_index=edge_index, 
        edge_attr=edge_attr,
        vnf_context=vnf_context,
        network_state=network_state
    )
    
    # åˆ›å»ºç¼–ç å™¨
    config = {
        'dimensions': {
            'node_feature_dim': 8,
            'edge_feature_dim_full': 4,
            'vnf_context_dim': 6
        },
        'gnn': {
            'edge_aware': {
                'hidden_dim': 128,
                'output_dim': 256,
                'layers': 4
            }
        }
    }
    
    encoder = create_enhanced_edge_aware_encoder(config)
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    with torch.no_grad():
        output = encoder(data)
        print(f"âœ… å‰å‘ä¼ æ’­æµ‹è¯•:")
        print(f"   è¾“å…¥: {num_nodes}èŠ‚ç‚¹, {num_edges}è¾¹")
        print(f"   è¾“å‡º: {output.shape}")
        
        # æµ‹è¯•è¾¹é‡è¦æ€§æ˜ å°„
        importance_map = encoder.compute_edge_importance_map(data)
        print(f"âœ… è¾¹é‡è¦æ€§æ˜ å°„:")
        print(f"   é‡è¦æ€§æ¡ç›®æ•°: {len(importance_map)}")
        print(f"   ç¤ºä¾‹é‡è¦æ€§: {list(importance_map.values())[0]}")
        
        # æµ‹è¯•VNFé€‚åº”æ€§è¯„åˆ†
        adaptation_score = encoder.get_vnf_adaptation_score(data)
        print(f"âœ… VNFé€‚åº”æ€§è¯„åˆ†: {adaptation_score:.3f}")
        
        # æµ‹è¯•æ‰¹å¤„ç†
        batch_data = Batch.from_data_list([data, data])
        batch_output = encoder(batch_data)
        print(f"âœ… æ‰¹å¤„ç†æµ‹è¯•: {batch_output.shape}")
    
    print(f"\nğŸ‰ å¢å¼ºEdge-Aware GNNç¼–ç å™¨æµ‹è¯•é€šè¿‡!")
    print(f"æ ¸å¿ƒåŠŸèƒ½éªŒè¯:")
    print(f"  âœ… è¾¹æ³¨æ„åŠ›æœºåˆ¶")
    print(f"  âœ… è·¯å¾„è´¨é‡æ„ŸçŸ¥")
    print(f"  âœ… VNFä¸Šä¸‹æ–‡èåˆ")
    print(f"  âœ… åŠ¨æ€ç½‘ç»œçŠ¶æ€")
    print(f"  âœ… é‡è¦æ€§åˆ†æ")


if __name__ == "__main__":
    test_enhanced_gnn()